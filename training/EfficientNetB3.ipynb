{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4759bf69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.applications import EfficientNetB3\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec293afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = \"../data/new_data\"   \n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7a260428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9332 files belonging to 34 classes.\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    dataset_dir,\n",
    "    seed=42,\n",
    "    image_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe18b63c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: ['African Violet (Saintpaulia ionantha)', 'Aloe Vera', 'Begonia (Begonia spp.)', 'Birds Nest Fern (Asplenium nidus)', 'Boston Fern (Nephrolepis exaltata)', 'Calathea', 'Cast Iron Plant (Aspidistra elatior)', 'Chinese Money Plant (Pilea peperomioides)', 'Christmas Cactus (Schlumbergera bridgesii)', 'Chrysanthemum', 'Ctenanthe', 'Dracaena', 'Elephant Ear (Alocasia spp.)', 'English Ivy (Hedera helix)', 'Hyacinth (Hyacinthus orientalis)', 'Iron Cross begonia (Begonia masoniana)', 'Jade plant (Crassula ovata)', 'Money Tree (Pachira aquatica)', 'Orchid', 'Parlor Palm (Chamaedorea elegans)', 'Peace lily', 'Poinsettia (Euphorbia pulcherrima)', 'Polka Dot Plant (Hypoestes phyllostachya)', 'Ponytail Palm (Beaucarnea recurvata)', 'Pothos (Ivy arum)', 'Prayer Plant (Maranta leuconeura)', 'Rattlesnake Plant (Calathea lancifolia)', 'Rubber Plant (Ficus elastica)', 'Sago Palm (Cycas revoluta)', 'Schefflera', 'Snake plant (Sanseviera)', 'Tradescantia', 'Tulip', 'Venus Flytrap']\n",
      "34\n"
     ]
    }
   ],
   "source": [
    "class_names = dataset.class_names\n",
    "print(\"Classes:\", class_names)\n",
    "num_classes = len(class_names)\n",
    "print(num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "342c5447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Tulip': 299, 'Hyacinth (Hyacinthus orientalis)': 299, 'Rubber Plant (Ficus elastica)': 291, 'Begonia (Begonia spp.)': 234, 'Chinese Money Plant (Pilea peperomioides)': 299, 'Cast Iron Plant (Aspidistra elatior)': 266, 'Ponytail Palm (Beaucarnea recurvata)': 195, 'Dracaena': 260, 'Christmas Cactus (Schlumbergera bridgesii)': 299, 'Money Tree (Pachira aquatica)': 299, 'Polka Dot Plant (Hypoestes phyllostachya)': 299, 'Schefflera': 299, 'Sago Palm (Cycas revoluta)': 199, 'Chrysanthemum': 208, 'Jade plant (Crassula ovata)': 299, 'Birds Nest Fern (Asplenium nidus)': 290, 'Snake plant (Sanseviera)': 299, 'English Ivy (Hedera helix)': 240, 'Iron Cross begonia (Begonia masoniana)': 263, 'Rattlesnake Plant (Calathea lancifolia)': 299, 'Aloe Vera': 247, 'Peace lily': 299, 'Ctenanthe': 293, 'Boston Fern (Nephrolepis exaltata)': 296, 'Parlor Palm (Chamaedorea elegans)': 299, 'Venus Flytrap': 196, 'African Violet (Saintpaulia ionantha)': 298, 'Prayer Plant (Maranta leuconeura)': 299, 'Calathea': 299, 'Elephant Ear (Alocasia spp.)': 299, 'Poinsettia (Euphorbia pulcherrima)': 299, 'Pothos (Ivy arum)': 242, 'Orchid': 234, 'Tradescantia': 296}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "class_counts = {}\n",
    "for images, labels in dataset:\n",
    "    for label in labels.numpy():\n",
    "        class_counts[label] = class_counts.get(label, 0) + 1\n",
    "print({class_names[k]: v for k,v in class_counts.items()})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "88fca639",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset_partitions_tf(ds, train_split=0.8, val_split=0.1, test_split=0.1, shuffle=True, shuffle_size=10000):\n",
    "    ds_size = len(ds)\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(shuffle_size, seed=42)\n",
    "    train_size = int(train_split * ds_size)\n",
    "    val_size = int(val_split * ds_size)\n",
    "    train_ds = ds.take(train_size)\n",
    "    val_ds = ds.skip(train_size).take(val_size)\n",
    "    test_ds = ds.skip(train_size).skip(val_size)\n",
    "    return train_ds, val_ds, test_ds\n",
    "\n",
    "train_ds, val_ds, test_ds = get_dataset_partitions_tf(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b26a8eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "train_ds = train_ds.prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.prefetch(buffer_size=AUTOTUNE)\n",
    "test_ds = test_ds.prefetch(buffer_size=AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "81eec4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = tf.keras.Sequential([\n",
    "    layers.RandomFlip(\"horizontal\"),\n",
    "    layers.RandomRotation(0.1),\n",
    "    layers.RandomZoom(0.2),\n",
    "    layers.RandomContrast(0.1),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9cfa0b3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformFullIntV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomGetKeyCounter cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting AdjustContrastv2 cause Input \"contrast_factor\" of op 'AdjustContrastv2' expected to be loop invariant.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformFullIntV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomGetKeyCounter cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting AdjustContrastv2 cause Input \"contrast_factor\" of op 'AdjustContrastv2' expected to be loop invariant.\n"
     ]
    }
   ],
   "source": [
    "inputs = layers.Input(shape=(224, 224, 3))\n",
    "x = data_augmentation(inputs)\n",
    "\n",
    "\n",
    "x = preprocess_input(x)\n",
    "\n",
    "# --- Pretrained EfficientNetB3 base ---\n",
    "base_model = EfficientNetB3(\n",
    "    weights=\"imagenet\",\n",
    "    include_top=False,\n",
    "    input_tensor=x\n",
    ")\n",
    "\n",
    "base_model.trainable = False \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f3ec7969",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = layers.GlobalAveragePooling2D()(base_model.output)\n",
    "x = layers.Dropout(0.4)(x)   # regularization\n",
    "outputs = layers.Dense(len(class_names), activation=\"softmax\")(x)\n",
    "\n",
    "model = models.Model(inputs, outputs)\n",
    "\n",
    "# --- Compile ---\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),  # âœ… lower LR\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8c8c0b40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformFullIntV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomGetKeyCounter cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting AdjustContrastv2 cause Input \"contrast_factor\" of op 'AdjustContrastv2' expected to be loop invariant.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformFullIntV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomGetKeyCounter cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting AdjustContrastv2 cause Input \"contrast_factor\" of op 'AdjustContrastv2' expected to be loop invariant.\n",
      "233/233 [==============================] - 187s 608ms/step - loss: 3.3727 - accuracy: 0.0993 - val_loss: 3.0057 - val_accuracy: 0.2651\n",
      "Epoch 2/15\n",
      "233/233 [==============================] - 177s 616ms/step - loss: 2.9257 - accuracy: 0.2466 - val_loss: 2.6055 - val_accuracy: 0.4149\n",
      "Epoch 3/15\n",
      "233/233 [==============================] - 192s 661ms/step - loss: 2.5886 - accuracy: 0.3580 - val_loss: 2.3423 - val_accuracy: 0.4688\n",
      "Epoch 4/15\n",
      "233/233 [==============================] - 193s 657ms/step - loss: 2.3444 - accuracy: 0.4258 - val_loss: 2.0540 - val_accuracy: 0.5765\n",
      "Epoch 5/15\n",
      "233/233 [==============================] - 176s 585ms/step - loss: 2.1604 - accuracy: 0.4758 - val_loss: 1.8871 - val_accuracy: 0.6013\n",
      "Epoch 6/15\n",
      "233/233 [==============================] - 172s 596ms/step - loss: 2.0095 - accuracy: 0.5110 - val_loss: 1.7760 - val_accuracy: 0.6261\n",
      "Epoch 7/15\n",
      "233/233 [==============================] - 195s 655ms/step - loss: 1.8898 - accuracy: 0.5384 - val_loss: 1.7030 - val_accuracy: 0.6422\n",
      "Epoch 8/15\n",
      "233/233 [==============================] - 186s 634ms/step - loss: 1.7805 - accuracy: 0.5652 - val_loss: 1.5559 - val_accuracy: 0.6778\n",
      "Epoch 9/15\n",
      "233/233 [==============================] - 192s 659ms/step - loss: 1.7027 - accuracy: 0.5853 - val_loss: 1.5173 - val_accuracy: 0.6703\n",
      "Epoch 10/15\n",
      "233/233 [==============================] - 188s 642ms/step - loss: 1.6344 - accuracy: 0.5926 - val_loss: 1.4565 - val_accuracy: 0.6562\n",
      "Epoch 11/15\n",
      "233/233 [==============================] - 194s 662ms/step - loss: 1.5663 - accuracy: 0.6073 - val_loss: 1.3947 - val_accuracy: 0.6779\n",
      "Epoch 12/15\n",
      "233/233 [==============================] - 164s 565ms/step - loss: 1.4976 - accuracy: 0.6226 - val_loss: 1.3163 - val_accuracy: 0.7155\n",
      "Epoch 13/15\n",
      "233/233 [==============================] - 162s 553ms/step - loss: 1.4472 - accuracy: 0.6369 - val_loss: 1.2863 - val_accuracy: 0.7144\n",
      "Epoch 14/15\n",
      "233/233 [==============================] - 160s 543ms/step - loss: 1.4076 - accuracy: 0.6421 - val_loss: 1.2019 - val_accuracy: 0.7306\n",
      "Epoch 15/15\n",
      "233/233 [==============================] - 183s 641ms/step - loss: 1.3865 - accuracy: 0.6487 - val_loss: 1.2268 - val_accuracy: 0.7166\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=15,   # longer warmup\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3603020e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b2cd16c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.trainable = True\n",
    "fine_tune_at = len(base_model.layers) - 30  # unfreeze last 30 layers\n",
    "for layer in base_model.layers[:fine_tune_at]:\n",
    "    layer.trainable = False\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f19b7cf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformFullIntV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomGetKeyCounter cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting AdjustContrastv2 cause Input \"contrast_factor\" of op 'AdjustContrastv2' expected to be loop invariant.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformFullIntV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomGetKeyCounter cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting AdjustContrastv2 cause Input \"contrast_factor\" of op 'AdjustContrastv2' expected to be loop invariant.\n",
      "233/233 [==============================] - 202s 669ms/step - loss: 1.9011 - accuracy: 0.5349 - val_loss: 1.3322 - val_accuracy: 0.7037\n",
      "Epoch 2/30\n",
      "233/233 [==============================] - 175s 576ms/step - loss: 1.6895 - accuracy: 0.5963 - val_loss: 1.2764 - val_accuracy: 0.7155\n",
      "Epoch 3/30\n",
      "233/233 [==============================] - 165s 564ms/step - loss: 1.5232 - accuracy: 0.6333 - val_loss: 1.1342 - val_accuracy: 0.7522\n",
      "Epoch 4/30\n",
      "233/233 [==============================] - 165s 565ms/step - loss: 1.3942 - accuracy: 0.6656 - val_loss: 1.0200 - val_accuracy: 0.7620\n",
      "Epoch 5/30\n",
      "233/233 [==============================] - 164s 559ms/step - loss: 1.2911 - accuracy: 0.6832 - val_loss: 0.9381 - val_accuracy: 0.7812\n",
      "Epoch 6/30\n",
      "233/233 [==============================] - 166s 569ms/step - loss: 1.2006 - accuracy: 0.6965 - val_loss: 0.8523 - val_accuracy: 0.7899\n",
      "Epoch 7/30\n",
      "233/233 [==============================] - 167s 570ms/step - loss: 1.1267 - accuracy: 0.7196 - val_loss: 0.7888 - val_accuracy: 0.8050\n",
      "Epoch 8/30\n",
      "233/233 [==============================] - 186s 648ms/step - loss: 1.0607 - accuracy: 0.7347 - val_loss: 0.7285 - val_accuracy: 0.8222\n",
      "Epoch 9/30\n",
      "233/233 [==============================] - 189s 647ms/step - loss: 1.0061 - accuracy: 0.7374 - val_loss: 0.7341 - val_accuracy: 0.8071\n",
      "Epoch 10/30\n",
      "233/233 [==============================] - 189s 645ms/step - loss: 0.9559 - accuracy: 0.7500 - val_loss: 0.7007 - val_accuracy: 0.8244\n",
      "Epoch 11/30\n",
      "233/233 [==============================] - 188s 644ms/step - loss: 0.9193 - accuracy: 0.7583 - val_loss: 0.6262 - val_accuracy: 0.8362\n",
      "Epoch 12/30\n",
      "233/233 [==============================] - 187s 643ms/step - loss: 0.8889 - accuracy: 0.7667 - val_loss: 0.5977 - val_accuracy: 0.8470\n",
      "Epoch 13/30\n",
      "233/233 [==============================] - 186s 634ms/step - loss: 0.8294 - accuracy: 0.7805 - val_loss: 0.5431 - val_accuracy: 0.8502\n",
      "Epoch 14/30\n",
      "233/233 [==============================] - 190s 652ms/step - loss: 0.8104 - accuracy: 0.7894 - val_loss: 0.5703 - val_accuracy: 0.8578\n",
      "Epoch 15/30\n",
      "233/233 [==============================] - 186s 636ms/step - loss: 0.8039 - accuracy: 0.7830 - val_loss: 0.5534 - val_accuracy: 0.8578\n",
      "Epoch 16/30\n",
      "233/233 [==============================] - 164s 563ms/step - loss: 0.7570 - accuracy: 0.7937 - val_loss: 0.5412 - val_accuracy: 0.8524\n",
      "Epoch 17/30\n",
      "233/233 [==============================] - 182s 623ms/step - loss: 0.7418 - accuracy: 0.7975 - val_loss: 0.4936 - val_accuracy: 0.8739\n",
      "Epoch 18/30\n",
      "233/233 [==============================] - 176s 615ms/step - loss: 0.7192 - accuracy: 0.8034 - val_loss: 0.5005 - val_accuracy: 0.8624\n",
      "Epoch 19/30\n",
      "233/233 [==============================] - 187s 627ms/step - loss: 0.7034 - accuracy: 0.8053 - val_loss: 0.4604 - val_accuracy: 0.8901\n",
      "Epoch 20/30\n",
      "233/233 [==============================] - 165s 570ms/step - loss: 0.6704 - accuracy: 0.8156 - val_loss: 0.3911 - val_accuracy: 0.9095\n",
      "Epoch 21/30\n",
      "233/233 [==============================] - 164s 559ms/step - loss: 0.6551 - accuracy: 0.8260 - val_loss: 0.4028 - val_accuracy: 0.8912\n",
      "Epoch 22/30\n",
      "233/233 [==============================] - 167s 575ms/step - loss: 0.6458 - accuracy: 0.8182 - val_loss: 0.4127 - val_accuracy: 0.8793\n",
      "Epoch 23/30\n",
      "233/233 [==============================] - 159s 537ms/step - loss: 0.6331 - accuracy: 0.8271 - val_loss: 0.3953 - val_accuracy: 0.8901\n",
      "Epoch 24/30\n",
      "233/233 [==============================] - 168s 583ms/step - loss: 0.6152 - accuracy: 0.8290 - val_loss: 0.3969 - val_accuracy: 0.8944\n",
      "Epoch 25/30\n",
      "233/233 [==============================] - 185s 605ms/step - loss: 0.5976 - accuracy: 0.8361 - val_loss: 0.3886 - val_accuracy: 0.8847\n",
      "Epoch 26/30\n",
      "233/233 [==============================] - 184s 647ms/step - loss: 0.5771 - accuracy: 0.8383 - val_loss: 0.3659 - val_accuracy: 0.9041\n",
      "Epoch 27/30\n",
      "233/233 [==============================] - 191s 643ms/step - loss: 0.5632 - accuracy: 0.8438 - val_loss: 0.4153 - val_accuracy: 0.8793\n",
      "Epoch 28/30\n",
      "233/233 [==============================] - 187s 636ms/step - loss: 0.5710 - accuracy: 0.8434 - val_loss: 0.3741 - val_accuracy: 0.8912\n",
      "Epoch 29/30\n",
      "233/233 [==============================] - 188s 642ms/step - loss: 0.5417 - accuracy: 0.8481 - val_loss: 0.3497 - val_accuracy: 0.9106\n",
      "Epoch 30/30\n",
      "233/233 [==============================] - 186s 632ms/step - loss: 0.5357 - accuracy: 0.8487 - val_loss: 0.3362 - val_accuracy: 0.8996\n"
     ]
    }
   ],
   "source": [
    "history_fine = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=EPOCHS,\n",
    "    verbose=1\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b21483c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Training and Validation Accuracy')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "acc = history_fine.history['accuracy']\n",
    "val_acc = history_fine.history['val_accuracy']\n",
    "\n",
    "loss = history_fine.history['loss']\n",
    "val_loss = history_fine.history['val_' \\\n",
    "'loss']\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(range(EPOCHS), acc, label='Training Accuracy')\n",
    "plt.plot(range(EPOCHS), val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6c79d4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save only weights\n",
    "model.save_weights(\"EfficientNet_weights.h5\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "38d28f28",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Unable to serialize [2.0896919 2.1128857 2.1081853] to JSON. Unrecognized type <class 'tensorflow.python.framework.ops.EagerTensor'>.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEfficientNet_full_model.h5\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\anaconda\\ana\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32md:\\anaconda\\ana\\envs\\tf\\lib\\json\\__init__.py:238\u001b[0m, in \u001b[0;36mdumps\u001b[1;34m(obj, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    233\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONEncoder\n\u001b[0;32m    234\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    235\u001b[0m \u001b[43m    \u001b[49m\u001b[43mskipkeys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipkeys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mensure_ascii\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_ascii\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    236\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcheck_circular\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_circular\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nan\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    237\u001b[0m \u001b[43m    \u001b[49m\u001b[43mseparators\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseparators\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msort_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m--> 238\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\anaconda\\ana\\envs\\tf\\lib\\json\\encoder.py:199\u001b[0m, in \u001b[0;36mJSONEncoder.encode\u001b[1;34m(self, o)\u001b[0m\n\u001b[0;32m    195\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m encode_basestring(o)\n\u001b[0;32m    196\u001b[0m \u001b[38;5;66;03m# This doesn't pass the iterator directly to ''.join() because the\u001b[39;00m\n\u001b[0;32m    197\u001b[0m \u001b[38;5;66;03m# exceptions aren't as detailed.  The list call should be roughly\u001b[39;00m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;66;03m# equivalent to the PySequence_Fast that ''.join() would do.\u001b[39;00m\n\u001b[1;32m--> 199\u001b[0m chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_one_shot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    200\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(chunks, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[0;32m    201\u001b[0m     chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(chunks)\n",
      "File \u001b[1;32md:\\anaconda\\ana\\envs\\tf\\lib\\json\\encoder.py:257\u001b[0m, in \u001b[0;36mJSONEncoder.iterencode\u001b[1;34m(self, o, _one_shot)\u001b[0m\n\u001b[0;32m    252\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    253\u001b[0m     _iterencode \u001b[38;5;241m=\u001b[39m _make_iterencode(\n\u001b[0;32m    254\u001b[0m         markers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefault, _encoder, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindent, floatstr,\n\u001b[0;32m    255\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkey_separator, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitem_separator, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msort_keys,\n\u001b[0;32m    256\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mskipkeys, _one_shot)\n\u001b[1;32m--> 257\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_iterencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: Unable to serialize [2.0896919 2.1128857 2.1081853] to JSON. Unrecognized type <class 'tensorflow.python.framework.ops.EagerTensor'>."
     ]
    }
   ],
   "source": [
    "\n",
    "model.save(\"EfficientNet_full_model.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "66f224d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #6 (named stem_conv) due to mismatch in shape for weight stem_conv/kernel:0. Weight expects shape (3, 3, 3, 32). Received saved weight with shape (40, 3, 3, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #6 (named stem_conv) due to mismatch in shape for weight stem_conv/kernel:0. Weight expects shape (3, 3, 3, 32). Received saved weight with shape (40, 3, 3, 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #7 (named stem_bn) due to mismatch in shape for weight stem_bn/gamma:0. Weight expects shape (32,). Received saved weight with shape (40,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #7 (named stem_bn) due to mismatch in shape for weight stem_bn/gamma:0. Weight expects shape (32,). Received saved weight with shape (40,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #7 (named stem_bn) due to mismatch in shape for weight stem_bn/beta:0. Weight expects shape (32,). Received saved weight with shape (40,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #7 (named stem_bn) due to mismatch in shape for weight stem_bn/beta:0. Weight expects shape (32,). Received saved weight with shape (40,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #7 (named stem_bn) due to mismatch in shape for weight stem_bn/moving_mean:0. Weight expects shape (32,). Received saved weight with shape (40,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #7 (named stem_bn) due to mismatch in shape for weight stem_bn/moving_mean:0. Weight expects shape (32,). Received saved weight with shape (40,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #7 (named stem_bn) due to mismatch in shape for weight stem_bn/moving_variance:0. Weight expects shape (32,). Received saved weight with shape (40,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #7 (named stem_bn) due to mismatch in shape for weight stem_bn/moving_variance:0. Weight expects shape (32,). Received saved weight with shape (40,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #9 (named block1a_dwconv) due to mismatch in shape for weight block1a_dwconv/depthwise_kernel:0. Weight expects shape (3, 3, 32, 1). Received saved weight with shape (3, 3, 40, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #9 (named block1a_dwconv) due to mismatch in shape for weight block1a_dwconv/depthwise_kernel:0. Weight expects shape (3, 3, 32, 1). Received saved weight with shape (3, 3, 40, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #10 (named block1a_bn) due to mismatch in shape for weight block1a_bn/gamma:0. Weight expects shape (32,). Received saved weight with shape (40,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #10 (named block1a_bn) due to mismatch in shape for weight block1a_bn/gamma:0. Weight expects shape (32,). Received saved weight with shape (40,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #10 (named block1a_bn) due to mismatch in shape for weight block1a_bn/beta:0. Weight expects shape (32,). Received saved weight with shape (40,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #10 (named block1a_bn) due to mismatch in shape for weight block1a_bn/beta:0. Weight expects shape (32,). Received saved weight with shape (40,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #10 (named block1a_bn) due to mismatch in shape for weight block1a_bn/moving_mean:0. Weight expects shape (32,). Received saved weight with shape (40,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #10 (named block1a_bn) due to mismatch in shape for weight block1a_bn/moving_mean:0. Weight expects shape (32,). Received saved weight with shape (40,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #10 (named block1a_bn) due to mismatch in shape for weight block1a_bn/moving_variance:0. Weight expects shape (32,). Received saved weight with shape (40,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #10 (named block1a_bn) due to mismatch in shape for weight block1a_bn/moving_variance:0. Weight expects shape (32,). Received saved weight with shape (40,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #14 (named block1a_se_reduce) due to mismatch in shape for weight block1a_se_reduce/kernel:0. Weight expects shape (1, 1, 32, 8). Received saved weight with shape (10, 40, 1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #14 (named block1a_se_reduce) due to mismatch in shape for weight block1a_se_reduce/kernel:0. Weight expects shape (1, 1, 32, 8). Received saved weight with shape (10, 40, 1, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #14 (named block1a_se_reduce) due to mismatch in shape for weight block1a_se_reduce/bias:0. Weight expects shape (8,). Received saved weight with shape (10,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #14 (named block1a_se_reduce) due to mismatch in shape for weight block1a_se_reduce/bias:0. Weight expects shape (8,). Received saved weight with shape (10,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #15 (named block1a_se_expand) due to mismatch in shape for weight block1a_se_expand/kernel:0. Weight expects shape (1, 1, 8, 32). Received saved weight with shape (40, 10, 1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #15 (named block1a_se_expand) due to mismatch in shape for weight block1a_se_expand/kernel:0. Weight expects shape (1, 1, 8, 32). Received saved weight with shape (40, 10, 1, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #15 (named block1a_se_expand) due to mismatch in shape for weight block1a_se_expand/bias:0. Weight expects shape (32,). Received saved weight with shape (40,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #15 (named block1a_se_expand) due to mismatch in shape for weight block1a_se_expand/bias:0. Weight expects shape (32,). Received saved weight with shape (40,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #17 (named block1a_project_conv) due to mismatch in shape for weight block1a_project_conv/kernel:0. Weight expects shape (1, 1, 32, 16). Received saved weight with shape (24, 40, 1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #17 (named block1a_project_conv) due to mismatch in shape for weight block1a_project_conv/kernel:0. Weight expects shape (1, 1, 32, 16). Received saved weight with shape (24, 40, 1, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #18 (named block1a_project_bn) due to mismatch in shape for weight block1a_project_bn/gamma:0. Weight expects shape (16,). Received saved weight with shape (24,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #18 (named block1a_project_bn) due to mismatch in shape for weight block1a_project_bn/gamma:0. Weight expects shape (16,). Received saved weight with shape (24,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #18 (named block1a_project_bn) due to mismatch in shape for weight block1a_project_bn/beta:0. Weight expects shape (16,). Received saved weight with shape (24,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #18 (named block1a_project_bn) due to mismatch in shape for weight block1a_project_bn/beta:0. Weight expects shape (16,). Received saved weight with shape (24,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #18 (named block1a_project_bn) due to mismatch in shape for weight block1a_project_bn/moving_mean:0. Weight expects shape (16,). Received saved weight with shape (24,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #18 (named block1a_project_bn) due to mismatch in shape for weight block1a_project_bn/moving_mean:0. Weight expects shape (16,). Received saved weight with shape (24,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #18 (named block1a_project_bn) due to mismatch in shape for weight block1a_project_bn/moving_variance:0. Weight expects shape (16,). Received saved weight with shape (24,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #18 (named block1a_project_bn) due to mismatch in shape for weight block1a_project_bn/moving_variance:0. Weight expects shape (16,). Received saved weight with shape (24,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #31 (named block2a_expand_conv) due to mismatch in shape for weight block2a_expand_conv/kernel:0. Weight expects shape (1, 1, 16, 96). Received saved weight with shape (144, 24, 1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #31 (named block2a_expand_conv) due to mismatch in shape for weight block2a_expand_conv/kernel:0. Weight expects shape (1, 1, 16, 96). Received saved weight with shape (144, 24, 1, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #32 (named block2a_expand_bn) due to mismatch in shape for weight block2a_expand_bn/gamma:0. Weight expects shape (96,). Received saved weight with shape (144,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #32 (named block2a_expand_bn) due to mismatch in shape for weight block2a_expand_bn/gamma:0. Weight expects shape (96,). Received saved weight with shape (144,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #32 (named block2a_expand_bn) due to mismatch in shape for weight block2a_expand_bn/beta:0. Weight expects shape (96,). Received saved weight with shape (144,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #32 (named block2a_expand_bn) due to mismatch in shape for weight block2a_expand_bn/beta:0. Weight expects shape (96,). Received saved weight with shape (144,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #32 (named block2a_expand_bn) due to mismatch in shape for weight block2a_expand_bn/moving_mean:0. Weight expects shape (96,). Received saved weight with shape (144,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #32 (named block2a_expand_bn) due to mismatch in shape for weight block2a_expand_bn/moving_mean:0. Weight expects shape (96,). Received saved weight with shape (144,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #32 (named block2a_expand_bn) due to mismatch in shape for weight block2a_expand_bn/moving_variance:0. Weight expects shape (96,). Received saved weight with shape (144,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #32 (named block2a_expand_bn) due to mismatch in shape for weight block2a_expand_bn/moving_variance:0. Weight expects shape (96,). Received saved weight with shape (144,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #35 (named block2a_dwconv) due to mismatch in shape for weight block2a_dwconv/depthwise_kernel:0. Weight expects shape (3, 3, 96, 1). Received saved weight with shape (3, 3, 144, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #35 (named block2a_dwconv) due to mismatch in shape for weight block2a_dwconv/depthwise_kernel:0. Weight expects shape (3, 3, 96, 1). Received saved weight with shape (3, 3, 144, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #36 (named block2a_bn) due to mismatch in shape for weight block2a_bn/gamma:0. Weight expects shape (96,). Received saved weight with shape (144,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #36 (named block2a_bn) due to mismatch in shape for weight block2a_bn/gamma:0. Weight expects shape (96,). Received saved weight with shape (144,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #36 (named block2a_bn) due to mismatch in shape for weight block2a_bn/beta:0. Weight expects shape (96,). Received saved weight with shape (144,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #36 (named block2a_bn) due to mismatch in shape for weight block2a_bn/beta:0. Weight expects shape (96,). Received saved weight with shape (144,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #36 (named block2a_bn) due to mismatch in shape for weight block2a_bn/moving_mean:0. Weight expects shape (96,). Received saved weight with shape (144,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #36 (named block2a_bn) due to mismatch in shape for weight block2a_bn/moving_mean:0. Weight expects shape (96,). Received saved weight with shape (144,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #36 (named block2a_bn) due to mismatch in shape for weight block2a_bn/moving_variance:0. Weight expects shape (96,). Received saved weight with shape (144,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #36 (named block2a_bn) due to mismatch in shape for weight block2a_bn/moving_variance:0. Weight expects shape (96,). Received saved weight with shape (144,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #40 (named block2a_se_reduce) due to mismatch in shape for weight block2a_se_reduce/kernel:0. Weight expects shape (1, 1, 96, 4). Received saved weight with shape (6, 144, 1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #40 (named block2a_se_reduce) due to mismatch in shape for weight block2a_se_reduce/kernel:0. Weight expects shape (1, 1, 96, 4). Received saved weight with shape (6, 144, 1, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #40 (named block2a_se_reduce) due to mismatch in shape for weight block2a_se_reduce/bias:0. Weight expects shape (4,). Received saved weight with shape (6,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #40 (named block2a_se_reduce) due to mismatch in shape for weight block2a_se_reduce/bias:0. Weight expects shape (4,). Received saved weight with shape (6,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #41 (named block2a_se_expand) due to mismatch in shape for weight block2a_se_expand/kernel:0. Weight expects shape (1, 1, 4, 96). Received saved weight with shape (144, 6, 1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #41 (named block2a_se_expand) due to mismatch in shape for weight block2a_se_expand/kernel:0. Weight expects shape (1, 1, 4, 96). Received saved weight with shape (144, 6, 1, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #41 (named block2a_se_expand) due to mismatch in shape for weight block2a_se_expand/bias:0. Weight expects shape (96,). Received saved weight with shape (144,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #41 (named block2a_se_expand) due to mismatch in shape for weight block2a_se_expand/bias:0. Weight expects shape (96,). Received saved weight with shape (144,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #43 (named block2a_project_conv) due to mismatch in shape for weight block2a_project_conv/kernel:0. Weight expects shape (1, 1, 96, 24). Received saved weight with shape (32, 144, 1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #43 (named block2a_project_conv) due to mismatch in shape for weight block2a_project_conv/kernel:0. Weight expects shape (1, 1, 96, 24). Received saved weight with shape (32, 144, 1, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #44 (named block2a_project_bn) due to mismatch in shape for weight block2a_project_bn/gamma:0. Weight expects shape (24,). Received saved weight with shape (32,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #44 (named block2a_project_bn) due to mismatch in shape for weight block2a_project_bn/gamma:0. Weight expects shape (24,). Received saved weight with shape (32,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #44 (named block2a_project_bn) due to mismatch in shape for weight block2a_project_bn/beta:0. Weight expects shape (24,). Received saved weight with shape (32,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #44 (named block2a_project_bn) due to mismatch in shape for weight block2a_project_bn/beta:0. Weight expects shape (24,). Received saved weight with shape (32,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #44 (named block2a_project_bn) due to mismatch in shape for weight block2a_project_bn/moving_mean:0. Weight expects shape (24,). Received saved weight with shape (32,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #44 (named block2a_project_bn) due to mismatch in shape for weight block2a_project_bn/moving_mean:0. Weight expects shape (24,). Received saved weight with shape (32,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #44 (named block2a_project_bn) due to mismatch in shape for weight block2a_project_bn/moving_variance:0. Weight expects shape (24,). Received saved weight with shape (32,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #44 (named block2a_project_bn) due to mismatch in shape for weight block2a_project_bn/moving_variance:0. Weight expects shape (24,). Received saved weight with shape (32,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #45 (named block2b_expand_conv) due to mismatch in shape for weight block2b_expand_conv/kernel:0. Weight expects shape (1, 1, 24, 144). Received saved weight with shape (192, 32, 1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #45 (named block2b_expand_conv) due to mismatch in shape for weight block2b_expand_conv/kernel:0. Weight expects shape (1, 1, 24, 144). Received saved weight with shape (192, 32, 1, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #46 (named block2b_expand_bn) due to mismatch in shape for weight block2b_expand_bn/gamma:0. Weight expects shape (144,). Received saved weight with shape (192,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #46 (named block2b_expand_bn) due to mismatch in shape for weight block2b_expand_bn/gamma:0. Weight expects shape (144,). Received saved weight with shape (192,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #46 (named block2b_expand_bn) due to mismatch in shape for weight block2b_expand_bn/beta:0. Weight expects shape (144,). Received saved weight with shape (192,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #46 (named block2b_expand_bn) due to mismatch in shape for weight block2b_expand_bn/beta:0. Weight expects shape (144,). Received saved weight with shape (192,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #46 (named block2b_expand_bn) due to mismatch in shape for weight block2b_expand_bn/moving_mean:0. Weight expects shape (144,). Received saved weight with shape (192,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #46 (named block2b_expand_bn) due to mismatch in shape for weight block2b_expand_bn/moving_mean:0. Weight expects shape (144,). Received saved weight with shape (192,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #46 (named block2b_expand_bn) due to mismatch in shape for weight block2b_expand_bn/moving_variance:0. Weight expects shape (144,). Received saved weight with shape (192,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #46 (named block2b_expand_bn) due to mismatch in shape for weight block2b_expand_bn/moving_variance:0. Weight expects shape (144,). Received saved weight with shape (192,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #48 (named block2b_dwconv) due to mismatch in shape for weight block2b_dwconv/depthwise_kernel:0. Weight expects shape (3, 3, 144, 1). Received saved weight with shape (3, 3, 192, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #48 (named block2b_dwconv) due to mismatch in shape for weight block2b_dwconv/depthwise_kernel:0. Weight expects shape (3, 3, 144, 1). Received saved weight with shape (3, 3, 192, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #49 (named block2b_bn) due to mismatch in shape for weight block2b_bn/gamma:0. Weight expects shape (144,). Received saved weight with shape (192,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #49 (named block2b_bn) due to mismatch in shape for weight block2b_bn/gamma:0. Weight expects shape (144,). Received saved weight with shape (192,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #49 (named block2b_bn) due to mismatch in shape for weight block2b_bn/beta:0. Weight expects shape (144,). Received saved weight with shape (192,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #49 (named block2b_bn) due to mismatch in shape for weight block2b_bn/beta:0. Weight expects shape (144,). Received saved weight with shape (192,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #49 (named block2b_bn) due to mismatch in shape for weight block2b_bn/moving_mean:0. Weight expects shape (144,). Received saved weight with shape (192,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #49 (named block2b_bn) due to mismatch in shape for weight block2b_bn/moving_mean:0. Weight expects shape (144,). Received saved weight with shape (192,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #49 (named block2b_bn) due to mismatch in shape for weight block2b_bn/moving_variance:0. Weight expects shape (144,). Received saved weight with shape (192,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #49 (named block2b_bn) due to mismatch in shape for weight block2b_bn/moving_variance:0. Weight expects shape (144,). Received saved weight with shape (192,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #53 (named block2b_se_reduce) due to mismatch in shape for weight block2b_se_reduce/kernel:0. Weight expects shape (1, 1, 144, 6). Received saved weight with shape (8, 192, 1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #53 (named block2b_se_reduce) due to mismatch in shape for weight block2b_se_reduce/kernel:0. Weight expects shape (1, 1, 144, 6). Received saved weight with shape (8, 192, 1, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #53 (named block2b_se_reduce) due to mismatch in shape for weight block2b_se_reduce/bias:0. Weight expects shape (6,). Received saved weight with shape (8,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #53 (named block2b_se_reduce) due to mismatch in shape for weight block2b_se_reduce/bias:0. Weight expects shape (6,). Received saved weight with shape (8,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #54 (named block2b_se_expand) due to mismatch in shape for weight block2b_se_expand/kernel:0. Weight expects shape (1, 1, 6, 144). Received saved weight with shape (192, 8, 1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #54 (named block2b_se_expand) due to mismatch in shape for weight block2b_se_expand/kernel:0. Weight expects shape (1, 1, 6, 144). Received saved weight with shape (192, 8, 1, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #54 (named block2b_se_expand) due to mismatch in shape for weight block2b_se_expand/bias:0. Weight expects shape (144,). Received saved weight with shape (192,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #54 (named block2b_se_expand) due to mismatch in shape for weight block2b_se_expand/bias:0. Weight expects shape (144,). Received saved weight with shape (192,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #56 (named block2b_project_conv) due to mismatch in shape for weight block2b_project_conv/kernel:0. Weight expects shape (1, 1, 144, 24). Received saved weight with shape (32, 192, 1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #56 (named block2b_project_conv) due to mismatch in shape for weight block2b_project_conv/kernel:0. Weight expects shape (1, 1, 144, 24). Received saved weight with shape (32, 192, 1, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #57 (named block2b_project_bn) due to mismatch in shape for weight block2b_project_bn/gamma:0. Weight expects shape (24,). Received saved weight with shape (32,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #57 (named block2b_project_bn) due to mismatch in shape for weight block2b_project_bn/gamma:0. Weight expects shape (24,). Received saved weight with shape (32,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #57 (named block2b_project_bn) due to mismatch in shape for weight block2b_project_bn/beta:0. Weight expects shape (24,). Received saved weight with shape (32,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #57 (named block2b_project_bn) due to mismatch in shape for weight block2b_project_bn/beta:0. Weight expects shape (24,). Received saved weight with shape (32,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #57 (named block2b_project_bn) due to mismatch in shape for weight block2b_project_bn/moving_mean:0. Weight expects shape (24,). Received saved weight with shape (32,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #57 (named block2b_project_bn) due to mismatch in shape for weight block2b_project_bn/moving_mean:0. Weight expects shape (24,). Received saved weight with shape (32,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #57 (named block2b_project_bn) due to mismatch in shape for weight block2b_project_bn/moving_variance:0. Weight expects shape (24,). Received saved weight with shape (32,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #57 (named block2b_project_bn) due to mismatch in shape for weight block2b_project_bn/moving_variance:0. Weight expects shape (24,). Received saved weight with shape (32,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #75 (named block3a_expand_conv) due to mismatch in shape for weight block3a_expand_conv/kernel:0. Weight expects shape (1, 1, 24, 144). Received saved weight with shape (192, 32, 1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #75 (named block3a_expand_conv) due to mismatch in shape for weight block3a_expand_conv/kernel:0. Weight expects shape (1, 1, 24, 144). Received saved weight with shape (192, 32, 1, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #76 (named block3a_expand_bn) due to mismatch in shape for weight block3a_expand_bn/gamma:0. Weight expects shape (144,). Received saved weight with shape (192,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #76 (named block3a_expand_bn) due to mismatch in shape for weight block3a_expand_bn/gamma:0. Weight expects shape (144,). Received saved weight with shape (192,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #76 (named block3a_expand_bn) due to mismatch in shape for weight block3a_expand_bn/beta:0. Weight expects shape (144,). Received saved weight with shape (192,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #76 (named block3a_expand_bn) due to mismatch in shape for weight block3a_expand_bn/beta:0. Weight expects shape (144,). Received saved weight with shape (192,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #76 (named block3a_expand_bn) due to mismatch in shape for weight block3a_expand_bn/moving_mean:0. Weight expects shape (144,). Received saved weight with shape (192,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #76 (named block3a_expand_bn) due to mismatch in shape for weight block3a_expand_bn/moving_mean:0. Weight expects shape (144,). Received saved weight with shape (192,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #76 (named block3a_expand_bn) due to mismatch in shape for weight block3a_expand_bn/moving_variance:0. Weight expects shape (144,). Received saved weight with shape (192,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #76 (named block3a_expand_bn) due to mismatch in shape for weight block3a_expand_bn/moving_variance:0. Weight expects shape (144,). Received saved weight with shape (192,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #79 (named block3a_dwconv) due to mismatch in shape for weight block3a_dwconv/depthwise_kernel:0. Weight expects shape (5, 5, 144, 1). Received saved weight with shape (5, 5, 192, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #79 (named block3a_dwconv) due to mismatch in shape for weight block3a_dwconv/depthwise_kernel:0. Weight expects shape (5, 5, 144, 1). Received saved weight with shape (5, 5, 192, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #80 (named block3a_bn) due to mismatch in shape for weight block3a_bn/gamma:0. Weight expects shape (144,). Received saved weight with shape (192,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #80 (named block3a_bn) due to mismatch in shape for weight block3a_bn/gamma:0. Weight expects shape (144,). Received saved weight with shape (192,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #80 (named block3a_bn) due to mismatch in shape for weight block3a_bn/beta:0. Weight expects shape (144,). Received saved weight with shape (192,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #80 (named block3a_bn) due to mismatch in shape for weight block3a_bn/beta:0. Weight expects shape (144,). Received saved weight with shape (192,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #80 (named block3a_bn) due to mismatch in shape for weight block3a_bn/moving_mean:0. Weight expects shape (144,). Received saved weight with shape (192,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #80 (named block3a_bn) due to mismatch in shape for weight block3a_bn/moving_mean:0. Weight expects shape (144,). Received saved weight with shape (192,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #80 (named block3a_bn) due to mismatch in shape for weight block3a_bn/moving_variance:0. Weight expects shape (144,). Received saved weight with shape (192,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #80 (named block3a_bn) due to mismatch in shape for weight block3a_bn/moving_variance:0. Weight expects shape (144,). Received saved weight with shape (192,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #84 (named block3a_se_reduce) due to mismatch in shape for weight block3a_se_reduce/kernel:0. Weight expects shape (1, 1, 144, 6). Received saved weight with shape (8, 192, 1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #84 (named block3a_se_reduce) due to mismatch in shape for weight block3a_se_reduce/kernel:0. Weight expects shape (1, 1, 144, 6). Received saved weight with shape (8, 192, 1, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #84 (named block3a_se_reduce) due to mismatch in shape for weight block3a_se_reduce/bias:0. Weight expects shape (6,). Received saved weight with shape (8,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #84 (named block3a_se_reduce) due to mismatch in shape for weight block3a_se_reduce/bias:0. Weight expects shape (6,). Received saved weight with shape (8,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #85 (named block3a_se_expand) due to mismatch in shape for weight block3a_se_expand/kernel:0. Weight expects shape (1, 1, 6, 144). Received saved weight with shape (192, 8, 1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #85 (named block3a_se_expand) due to mismatch in shape for weight block3a_se_expand/kernel:0. Weight expects shape (1, 1, 6, 144). Received saved weight with shape (192, 8, 1, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #85 (named block3a_se_expand) due to mismatch in shape for weight block3a_se_expand/bias:0. Weight expects shape (144,). Received saved weight with shape (192,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #85 (named block3a_se_expand) due to mismatch in shape for weight block3a_se_expand/bias:0. Weight expects shape (144,). Received saved weight with shape (192,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #87 (named block3a_project_conv) due to mismatch in shape for weight block3a_project_conv/kernel:0. Weight expects shape (1, 1, 144, 40). Received saved weight with shape (48, 192, 1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #87 (named block3a_project_conv) due to mismatch in shape for weight block3a_project_conv/kernel:0. Weight expects shape (1, 1, 144, 40). Received saved weight with shape (48, 192, 1, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #88 (named block3a_project_bn) due to mismatch in shape for weight block3a_project_bn/gamma:0. Weight expects shape (40,). Received saved weight with shape (48,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #88 (named block3a_project_bn) due to mismatch in shape for weight block3a_project_bn/gamma:0. Weight expects shape (40,). Received saved weight with shape (48,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #88 (named block3a_project_bn) due to mismatch in shape for weight block3a_project_bn/beta:0. Weight expects shape (40,). Received saved weight with shape (48,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #88 (named block3a_project_bn) due to mismatch in shape for weight block3a_project_bn/beta:0. Weight expects shape (40,). Received saved weight with shape (48,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #88 (named block3a_project_bn) due to mismatch in shape for weight block3a_project_bn/moving_mean:0. Weight expects shape (40,). Received saved weight with shape (48,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #88 (named block3a_project_bn) due to mismatch in shape for weight block3a_project_bn/moving_mean:0. Weight expects shape (40,). Received saved weight with shape (48,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #88 (named block3a_project_bn) due to mismatch in shape for weight block3a_project_bn/moving_variance:0. Weight expects shape (40,). Received saved weight with shape (48,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #88 (named block3a_project_bn) due to mismatch in shape for weight block3a_project_bn/moving_variance:0. Weight expects shape (40,). Received saved weight with shape (48,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #89 (named block3b_expand_conv) due to mismatch in shape for weight block3b_expand_conv/kernel:0. Weight expects shape (1, 1, 40, 240). Received saved weight with shape (288, 48, 1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #89 (named block3b_expand_conv) due to mismatch in shape for weight block3b_expand_conv/kernel:0. Weight expects shape (1, 1, 40, 240). Received saved weight with shape (288, 48, 1, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #90 (named block3b_expand_bn) due to mismatch in shape for weight block3b_expand_bn/gamma:0. Weight expects shape (240,). Received saved weight with shape (288,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #90 (named block3b_expand_bn) due to mismatch in shape for weight block3b_expand_bn/gamma:0. Weight expects shape (240,). Received saved weight with shape (288,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #90 (named block3b_expand_bn) due to mismatch in shape for weight block3b_expand_bn/beta:0. Weight expects shape (240,). Received saved weight with shape (288,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #90 (named block3b_expand_bn) due to mismatch in shape for weight block3b_expand_bn/beta:0. Weight expects shape (240,). Received saved weight with shape (288,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #90 (named block3b_expand_bn) due to mismatch in shape for weight block3b_expand_bn/moving_mean:0. Weight expects shape (240,). Received saved weight with shape (288,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #90 (named block3b_expand_bn) due to mismatch in shape for weight block3b_expand_bn/moving_mean:0. Weight expects shape (240,). Received saved weight with shape (288,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #90 (named block3b_expand_bn) due to mismatch in shape for weight block3b_expand_bn/moving_variance:0. Weight expects shape (240,). Received saved weight with shape (288,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #90 (named block3b_expand_bn) due to mismatch in shape for weight block3b_expand_bn/moving_variance:0. Weight expects shape (240,). Received saved weight with shape (288,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #92 (named block3b_dwconv) due to mismatch in shape for weight block3b_dwconv/depthwise_kernel:0. Weight expects shape (5, 5, 240, 1). Received saved weight with shape (5, 5, 288, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #92 (named block3b_dwconv) due to mismatch in shape for weight block3b_dwconv/depthwise_kernel:0. Weight expects shape (5, 5, 240, 1). Received saved weight with shape (5, 5, 288, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #93 (named block3b_bn) due to mismatch in shape for weight block3b_bn/gamma:0. Weight expects shape (240,). Received saved weight with shape (288,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #93 (named block3b_bn) due to mismatch in shape for weight block3b_bn/gamma:0. Weight expects shape (240,). Received saved weight with shape (288,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #93 (named block3b_bn) due to mismatch in shape for weight block3b_bn/beta:0. Weight expects shape (240,). Received saved weight with shape (288,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #93 (named block3b_bn) due to mismatch in shape for weight block3b_bn/beta:0. Weight expects shape (240,). Received saved weight with shape (288,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #93 (named block3b_bn) due to mismatch in shape for weight block3b_bn/moving_mean:0. Weight expects shape (240,). Received saved weight with shape (288,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #93 (named block3b_bn) due to mismatch in shape for weight block3b_bn/moving_mean:0. Weight expects shape (240,). Received saved weight with shape (288,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #93 (named block3b_bn) due to mismatch in shape for weight block3b_bn/moving_variance:0. Weight expects shape (240,). Received saved weight with shape (288,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #93 (named block3b_bn) due to mismatch in shape for weight block3b_bn/moving_variance:0. Weight expects shape (240,). Received saved weight with shape (288,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #97 (named block3b_se_reduce) due to mismatch in shape for weight block3b_se_reduce/kernel:0. Weight expects shape (1, 1, 240, 10). Received saved weight with shape (12, 288, 1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #97 (named block3b_se_reduce) due to mismatch in shape for weight block3b_se_reduce/kernel:0. Weight expects shape (1, 1, 240, 10). Received saved weight with shape (12, 288, 1, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #97 (named block3b_se_reduce) due to mismatch in shape for weight block3b_se_reduce/bias:0. Weight expects shape (10,). Received saved weight with shape (12,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #97 (named block3b_se_reduce) due to mismatch in shape for weight block3b_se_reduce/bias:0. Weight expects shape (10,). Received saved weight with shape (12,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #98 (named block3b_se_expand) due to mismatch in shape for weight block3b_se_expand/kernel:0. Weight expects shape (1, 1, 10, 240). Received saved weight with shape (288, 12, 1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #98 (named block3b_se_expand) due to mismatch in shape for weight block3b_se_expand/kernel:0. Weight expects shape (1, 1, 10, 240). Received saved weight with shape (288, 12, 1, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #98 (named block3b_se_expand) due to mismatch in shape for weight block3b_se_expand/bias:0. Weight expects shape (240,). Received saved weight with shape (288,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #98 (named block3b_se_expand) due to mismatch in shape for weight block3b_se_expand/bias:0. Weight expects shape (240,). Received saved weight with shape (288,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #100 (named block3b_project_conv) due to mismatch in shape for weight block3b_project_conv/kernel:0. Weight expects shape (1, 1, 240, 40). Received saved weight with shape (48, 288, 1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #100 (named block3b_project_conv) due to mismatch in shape for weight block3b_project_conv/kernel:0. Weight expects shape (1, 1, 240, 40). Received saved weight with shape (48, 288, 1, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #101 (named block3b_project_bn) due to mismatch in shape for weight block3b_project_bn/gamma:0. Weight expects shape (40,). Received saved weight with shape (48,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #101 (named block3b_project_bn) due to mismatch in shape for weight block3b_project_bn/gamma:0. Weight expects shape (40,). Received saved weight with shape (48,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #101 (named block3b_project_bn) due to mismatch in shape for weight block3b_project_bn/beta:0. Weight expects shape (40,). Received saved weight with shape (48,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #101 (named block3b_project_bn) due to mismatch in shape for weight block3b_project_bn/beta:0. Weight expects shape (40,). Received saved weight with shape (48,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #101 (named block3b_project_bn) due to mismatch in shape for weight block3b_project_bn/moving_mean:0. Weight expects shape (40,). Received saved weight with shape (48,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #101 (named block3b_project_bn) due to mismatch in shape for weight block3b_project_bn/moving_mean:0. Weight expects shape (40,). Received saved weight with shape (48,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #101 (named block3b_project_bn) due to mismatch in shape for weight block3b_project_bn/moving_variance:0. Weight expects shape (40,). Received saved weight with shape (48,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #101 (named block3b_project_bn) due to mismatch in shape for weight block3b_project_bn/moving_variance:0. Weight expects shape (40,). Received saved weight with shape (48,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #119 (named block4a_expand_conv) due to mismatch in shape for weight block4a_expand_conv/kernel:0. Weight expects shape (1, 1, 40, 240). Received saved weight with shape (288, 48, 1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #119 (named block4a_expand_conv) due to mismatch in shape for weight block4a_expand_conv/kernel:0. Weight expects shape (1, 1, 40, 240). Received saved weight with shape (288, 48, 1, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #120 (named block4a_expand_bn) due to mismatch in shape for weight block4a_expand_bn/gamma:0. Weight expects shape (240,). Received saved weight with shape (288,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #120 (named block4a_expand_bn) due to mismatch in shape for weight block4a_expand_bn/gamma:0. Weight expects shape (240,). Received saved weight with shape (288,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #120 (named block4a_expand_bn) due to mismatch in shape for weight block4a_expand_bn/beta:0. Weight expects shape (240,). Received saved weight with shape (288,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #120 (named block4a_expand_bn) due to mismatch in shape for weight block4a_expand_bn/beta:0. Weight expects shape (240,). Received saved weight with shape (288,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #120 (named block4a_expand_bn) due to mismatch in shape for weight block4a_expand_bn/moving_mean:0. Weight expects shape (240,). Received saved weight with shape (288,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #120 (named block4a_expand_bn) due to mismatch in shape for weight block4a_expand_bn/moving_mean:0. Weight expects shape (240,). Received saved weight with shape (288,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #120 (named block4a_expand_bn) due to mismatch in shape for weight block4a_expand_bn/moving_variance:0. Weight expects shape (240,). Received saved weight with shape (288,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #120 (named block4a_expand_bn) due to mismatch in shape for weight block4a_expand_bn/moving_variance:0. Weight expects shape (240,). Received saved weight with shape (288,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #123 (named block4a_dwconv) due to mismatch in shape for weight block4a_dwconv/depthwise_kernel:0. Weight expects shape (3, 3, 240, 1). Received saved weight with shape (3, 3, 288, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #123 (named block4a_dwconv) due to mismatch in shape for weight block4a_dwconv/depthwise_kernel:0. Weight expects shape (3, 3, 240, 1). Received saved weight with shape (3, 3, 288, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #124 (named block4a_bn) due to mismatch in shape for weight block4a_bn/gamma:0. Weight expects shape (240,). Received saved weight with shape (288,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #124 (named block4a_bn) due to mismatch in shape for weight block4a_bn/gamma:0. Weight expects shape (240,). Received saved weight with shape (288,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #124 (named block4a_bn) due to mismatch in shape for weight block4a_bn/beta:0. Weight expects shape (240,). Received saved weight with shape (288,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #124 (named block4a_bn) due to mismatch in shape for weight block4a_bn/beta:0. Weight expects shape (240,). Received saved weight with shape (288,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #124 (named block4a_bn) due to mismatch in shape for weight block4a_bn/moving_mean:0. Weight expects shape (240,). Received saved weight with shape (288,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #124 (named block4a_bn) due to mismatch in shape for weight block4a_bn/moving_mean:0. Weight expects shape (240,). Received saved weight with shape (288,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #124 (named block4a_bn) due to mismatch in shape for weight block4a_bn/moving_variance:0. Weight expects shape (240,). Received saved weight with shape (288,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #124 (named block4a_bn) due to mismatch in shape for weight block4a_bn/moving_variance:0. Weight expects shape (240,). Received saved weight with shape (288,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #128 (named block4a_se_reduce) due to mismatch in shape for weight block4a_se_reduce/kernel:0. Weight expects shape (1, 1, 240, 10). Received saved weight with shape (12, 288, 1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #128 (named block4a_se_reduce) due to mismatch in shape for weight block4a_se_reduce/kernel:0. Weight expects shape (1, 1, 240, 10). Received saved weight with shape (12, 288, 1, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #128 (named block4a_se_reduce) due to mismatch in shape for weight block4a_se_reduce/bias:0. Weight expects shape (10,). Received saved weight with shape (12,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #128 (named block4a_se_reduce) due to mismatch in shape for weight block4a_se_reduce/bias:0. Weight expects shape (10,). Received saved weight with shape (12,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #129 (named block4a_se_expand) due to mismatch in shape for weight block4a_se_expand/kernel:0. Weight expects shape (1, 1, 10, 240). Received saved weight with shape (288, 12, 1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #129 (named block4a_se_expand) due to mismatch in shape for weight block4a_se_expand/kernel:0. Weight expects shape (1, 1, 10, 240). Received saved weight with shape (288, 12, 1, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #129 (named block4a_se_expand) due to mismatch in shape for weight block4a_se_expand/bias:0. Weight expects shape (240,). Received saved weight with shape (288,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #129 (named block4a_se_expand) due to mismatch in shape for weight block4a_se_expand/bias:0. Weight expects shape (240,). Received saved weight with shape (288,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #131 (named block4a_project_conv) due to mismatch in shape for weight block4a_project_conv/kernel:0. Weight expects shape (1, 1, 240, 80). Received saved weight with shape (96, 288, 1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #131 (named block4a_project_conv) due to mismatch in shape for weight block4a_project_conv/kernel:0. Weight expects shape (1, 1, 240, 80). Received saved weight with shape (96, 288, 1, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #132 (named block4a_project_bn) due to mismatch in shape for weight block4a_project_bn/gamma:0. Weight expects shape (80,). Received saved weight with shape (96,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #132 (named block4a_project_bn) due to mismatch in shape for weight block4a_project_bn/gamma:0. Weight expects shape (80,). Received saved weight with shape (96,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #132 (named block4a_project_bn) due to mismatch in shape for weight block4a_project_bn/beta:0. Weight expects shape (80,). Received saved weight with shape (96,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #132 (named block4a_project_bn) due to mismatch in shape for weight block4a_project_bn/beta:0. Weight expects shape (80,). Received saved weight with shape (96,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #132 (named block4a_project_bn) due to mismatch in shape for weight block4a_project_bn/moving_mean:0. Weight expects shape (80,). Received saved weight with shape (96,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #132 (named block4a_project_bn) due to mismatch in shape for weight block4a_project_bn/moving_mean:0. Weight expects shape (80,). Received saved weight with shape (96,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #132 (named block4a_project_bn) due to mismatch in shape for weight block4a_project_bn/moving_variance:0. Weight expects shape (80,). Received saved weight with shape (96,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #132 (named block4a_project_bn) due to mismatch in shape for weight block4a_project_bn/moving_variance:0. Weight expects shape (80,). Received saved weight with shape (96,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #133 (named block4b_expand_conv) due to mismatch in shape for weight block4b_expand_conv/kernel:0. Weight expects shape (1, 1, 80, 480). Received saved weight with shape (576, 96, 1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #133 (named block4b_expand_conv) due to mismatch in shape for weight block4b_expand_conv/kernel:0. Weight expects shape (1, 1, 80, 480). Received saved weight with shape (576, 96, 1, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #134 (named block4b_expand_bn) due to mismatch in shape for weight block4b_expand_bn/gamma:0. Weight expects shape (480,). Received saved weight with shape (576,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #134 (named block4b_expand_bn) due to mismatch in shape for weight block4b_expand_bn/gamma:0. Weight expects shape (480,). Received saved weight with shape (576,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #134 (named block4b_expand_bn) due to mismatch in shape for weight block4b_expand_bn/beta:0. Weight expects shape (480,). Received saved weight with shape (576,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #134 (named block4b_expand_bn) due to mismatch in shape for weight block4b_expand_bn/beta:0. Weight expects shape (480,). Received saved weight with shape (576,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #134 (named block4b_expand_bn) due to mismatch in shape for weight block4b_expand_bn/moving_mean:0. Weight expects shape (480,). Received saved weight with shape (576,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #134 (named block4b_expand_bn) due to mismatch in shape for weight block4b_expand_bn/moving_mean:0. Weight expects shape (480,). Received saved weight with shape (576,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #134 (named block4b_expand_bn) due to mismatch in shape for weight block4b_expand_bn/moving_variance:0. Weight expects shape (480,). Received saved weight with shape (576,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #134 (named block4b_expand_bn) due to mismatch in shape for weight block4b_expand_bn/moving_variance:0. Weight expects shape (480,). Received saved weight with shape (576,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #136 (named block4b_dwconv) due to mismatch in shape for weight block4b_dwconv/depthwise_kernel:0. Weight expects shape (3, 3, 480, 1). Received saved weight with shape (3, 3, 576, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #136 (named block4b_dwconv) due to mismatch in shape for weight block4b_dwconv/depthwise_kernel:0. Weight expects shape (3, 3, 480, 1). Received saved weight with shape (3, 3, 576, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #137 (named block4b_bn) due to mismatch in shape for weight block4b_bn/gamma:0. Weight expects shape (480,). Received saved weight with shape (576,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #137 (named block4b_bn) due to mismatch in shape for weight block4b_bn/gamma:0. Weight expects shape (480,). Received saved weight with shape (576,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #137 (named block4b_bn) due to mismatch in shape for weight block4b_bn/beta:0. Weight expects shape (480,). Received saved weight with shape (576,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #137 (named block4b_bn) due to mismatch in shape for weight block4b_bn/beta:0. Weight expects shape (480,). Received saved weight with shape (576,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #137 (named block4b_bn) due to mismatch in shape for weight block4b_bn/moving_mean:0. Weight expects shape (480,). Received saved weight with shape (576,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #137 (named block4b_bn) due to mismatch in shape for weight block4b_bn/moving_mean:0. Weight expects shape (480,). Received saved weight with shape (576,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #137 (named block4b_bn) due to mismatch in shape for weight block4b_bn/moving_variance:0. Weight expects shape (480,). Received saved weight with shape (576,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #137 (named block4b_bn) due to mismatch in shape for weight block4b_bn/moving_variance:0. Weight expects shape (480,). Received saved weight with shape (576,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #141 (named block4b_se_reduce) due to mismatch in shape for weight block4b_se_reduce/kernel:0. Weight expects shape (1, 1, 480, 20). Received saved weight with shape (24, 576, 1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #141 (named block4b_se_reduce) due to mismatch in shape for weight block4b_se_reduce/kernel:0. Weight expects shape (1, 1, 480, 20). Received saved weight with shape (24, 576, 1, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #141 (named block4b_se_reduce) due to mismatch in shape for weight block4b_se_reduce/bias:0. Weight expects shape (20,). Received saved weight with shape (24,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #141 (named block4b_se_reduce) due to mismatch in shape for weight block4b_se_reduce/bias:0. Weight expects shape (20,). Received saved weight with shape (24,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #142 (named block4b_se_expand) due to mismatch in shape for weight block4b_se_expand/kernel:0. Weight expects shape (1, 1, 20, 480). Received saved weight with shape (576, 24, 1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #142 (named block4b_se_expand) due to mismatch in shape for weight block4b_se_expand/kernel:0. Weight expects shape (1, 1, 20, 480). Received saved weight with shape (576, 24, 1, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #142 (named block4b_se_expand) due to mismatch in shape for weight block4b_se_expand/bias:0. Weight expects shape (480,). Received saved weight with shape (576,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #142 (named block4b_se_expand) due to mismatch in shape for weight block4b_se_expand/bias:0. Weight expects shape (480,). Received saved weight with shape (576,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #144 (named block4b_project_conv) due to mismatch in shape for weight block4b_project_conv/kernel:0. Weight expects shape (1, 1, 480, 80). Received saved weight with shape (96, 576, 1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #144 (named block4b_project_conv) due to mismatch in shape for weight block4b_project_conv/kernel:0. Weight expects shape (1, 1, 480, 80). Received saved weight with shape (96, 576, 1, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #145 (named block4b_project_bn) due to mismatch in shape for weight block4b_project_bn/gamma:0. Weight expects shape (80,). Received saved weight with shape (96,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #145 (named block4b_project_bn) due to mismatch in shape for weight block4b_project_bn/gamma:0. Weight expects shape (80,). Received saved weight with shape (96,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #145 (named block4b_project_bn) due to mismatch in shape for weight block4b_project_bn/beta:0. Weight expects shape (80,). Received saved weight with shape (96,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #145 (named block4b_project_bn) due to mismatch in shape for weight block4b_project_bn/beta:0. Weight expects shape (80,). Received saved weight with shape (96,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #145 (named block4b_project_bn) due to mismatch in shape for weight block4b_project_bn/moving_mean:0. Weight expects shape (80,). Received saved weight with shape (96,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #145 (named block4b_project_bn) due to mismatch in shape for weight block4b_project_bn/moving_mean:0. Weight expects shape (80,). Received saved weight with shape (96,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #145 (named block4b_project_bn) due to mismatch in shape for weight block4b_project_bn/moving_variance:0. Weight expects shape (80,). Received saved weight with shape (96,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #145 (named block4b_project_bn) due to mismatch in shape for weight block4b_project_bn/moving_variance:0. Weight expects shape (80,). Received saved weight with shape (96,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #148 (named block4c_expand_conv) due to mismatch in shape for weight block4c_expand_conv/kernel:0. Weight expects shape (1, 1, 80, 480). Received saved weight with shape (576, 96, 1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #148 (named block4c_expand_conv) due to mismatch in shape for weight block4c_expand_conv/kernel:0. Weight expects shape (1, 1, 80, 480). Received saved weight with shape (576, 96, 1, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #149 (named block4c_expand_bn) due to mismatch in shape for weight block4c_expand_bn/gamma:0. Weight expects shape (480,). Received saved weight with shape (576,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #149 (named block4c_expand_bn) due to mismatch in shape for weight block4c_expand_bn/gamma:0. Weight expects shape (480,). Received saved weight with shape (576,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #149 (named block4c_expand_bn) due to mismatch in shape for weight block4c_expand_bn/beta:0. Weight expects shape (480,). Received saved weight with shape (576,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #149 (named block4c_expand_bn) due to mismatch in shape for weight block4c_expand_bn/beta:0. Weight expects shape (480,). Received saved weight with shape (576,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #149 (named block4c_expand_bn) due to mismatch in shape for weight block4c_expand_bn/moving_mean:0. Weight expects shape (480,). Received saved weight with shape (576,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #149 (named block4c_expand_bn) due to mismatch in shape for weight block4c_expand_bn/moving_mean:0. Weight expects shape (480,). Received saved weight with shape (576,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #149 (named block4c_expand_bn) due to mismatch in shape for weight block4c_expand_bn/moving_variance:0. Weight expects shape (480,). Received saved weight with shape (576,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #149 (named block4c_expand_bn) due to mismatch in shape for weight block4c_expand_bn/moving_variance:0. Weight expects shape (480,). Received saved weight with shape (576,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #151 (named block4c_dwconv) due to mismatch in shape for weight block4c_dwconv/depthwise_kernel:0. Weight expects shape (3, 3, 480, 1). Received saved weight with shape (3, 3, 576, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #151 (named block4c_dwconv) due to mismatch in shape for weight block4c_dwconv/depthwise_kernel:0. Weight expects shape (3, 3, 480, 1). Received saved weight with shape (3, 3, 576, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #152 (named block4c_bn) due to mismatch in shape for weight block4c_bn/gamma:0. Weight expects shape (480,). Received saved weight with shape (576,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #152 (named block4c_bn) due to mismatch in shape for weight block4c_bn/gamma:0. Weight expects shape (480,). Received saved weight with shape (576,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #152 (named block4c_bn) due to mismatch in shape for weight block4c_bn/beta:0. Weight expects shape (480,). Received saved weight with shape (576,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #152 (named block4c_bn) due to mismatch in shape for weight block4c_bn/beta:0. Weight expects shape (480,). Received saved weight with shape (576,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #152 (named block4c_bn) due to mismatch in shape for weight block4c_bn/moving_mean:0. Weight expects shape (480,). Received saved weight with shape (576,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #152 (named block4c_bn) due to mismatch in shape for weight block4c_bn/moving_mean:0. Weight expects shape (480,). Received saved weight with shape (576,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #152 (named block4c_bn) due to mismatch in shape for weight block4c_bn/moving_variance:0. Weight expects shape (480,). Received saved weight with shape (576,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #152 (named block4c_bn) due to mismatch in shape for weight block4c_bn/moving_variance:0. Weight expects shape (480,). Received saved weight with shape (576,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #156 (named block4c_se_reduce) due to mismatch in shape for weight block4c_se_reduce/kernel:0. Weight expects shape (1, 1, 480, 20). Received saved weight with shape (24, 576, 1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #156 (named block4c_se_reduce) due to mismatch in shape for weight block4c_se_reduce/kernel:0. Weight expects shape (1, 1, 480, 20). Received saved weight with shape (24, 576, 1, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #156 (named block4c_se_reduce) due to mismatch in shape for weight block4c_se_reduce/bias:0. Weight expects shape (20,). Received saved weight with shape (24,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #156 (named block4c_se_reduce) due to mismatch in shape for weight block4c_se_reduce/bias:0. Weight expects shape (20,). Received saved weight with shape (24,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #157 (named block4c_se_expand) due to mismatch in shape for weight block4c_se_expand/kernel:0. Weight expects shape (1, 1, 20, 480). Received saved weight with shape (576, 24, 1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #157 (named block4c_se_expand) due to mismatch in shape for weight block4c_se_expand/kernel:0. Weight expects shape (1, 1, 20, 480). Received saved weight with shape (576, 24, 1, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #157 (named block4c_se_expand) due to mismatch in shape for weight block4c_se_expand/bias:0. Weight expects shape (480,). Received saved weight with shape (576,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #157 (named block4c_se_expand) due to mismatch in shape for weight block4c_se_expand/bias:0. Weight expects shape (480,). Received saved weight with shape (576,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #159 (named block4c_project_conv) due to mismatch in shape for weight block4c_project_conv/kernel:0. Weight expects shape (1, 1, 480, 80). Received saved weight with shape (96, 576, 1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #159 (named block4c_project_conv) due to mismatch in shape for weight block4c_project_conv/kernel:0. Weight expects shape (1, 1, 480, 80). Received saved weight with shape (96, 576, 1, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #160 (named block4c_project_bn) due to mismatch in shape for weight block4c_project_bn/gamma:0. Weight expects shape (80,). Received saved weight with shape (96,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #160 (named block4c_project_bn) due to mismatch in shape for weight block4c_project_bn/gamma:0. Weight expects shape (80,). Received saved weight with shape (96,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #160 (named block4c_project_bn) due to mismatch in shape for weight block4c_project_bn/beta:0. Weight expects shape (80,). Received saved weight with shape (96,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #160 (named block4c_project_bn) due to mismatch in shape for weight block4c_project_bn/beta:0. Weight expects shape (80,). Received saved weight with shape (96,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #160 (named block4c_project_bn) due to mismatch in shape for weight block4c_project_bn/moving_mean:0. Weight expects shape (80,). Received saved weight with shape (96,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #160 (named block4c_project_bn) due to mismatch in shape for weight block4c_project_bn/moving_mean:0. Weight expects shape (80,). Received saved weight with shape (96,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #160 (named block4c_project_bn) due to mismatch in shape for weight block4c_project_bn/moving_variance:0. Weight expects shape (80,). Received saved weight with shape (96,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #160 (named block4c_project_bn) due to mismatch in shape for weight block4c_project_bn/moving_variance:0. Weight expects shape (80,). Received saved weight with shape (96,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #193 (named block5a_expand_conv) due to mismatch in shape for weight block5a_expand_conv/kernel:0. Weight expects shape (1, 1, 80, 480). Received saved weight with shape (576, 96, 1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #193 (named block5a_expand_conv) due to mismatch in shape for weight block5a_expand_conv/kernel:0. Weight expects shape (1, 1, 80, 480). Received saved weight with shape (576, 96, 1, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #194 (named block5a_expand_bn) due to mismatch in shape for weight block5a_expand_bn/gamma:0. Weight expects shape (480,). Received saved weight with shape (576,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #194 (named block5a_expand_bn) due to mismatch in shape for weight block5a_expand_bn/gamma:0. Weight expects shape (480,). Received saved weight with shape (576,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #194 (named block5a_expand_bn) due to mismatch in shape for weight block5a_expand_bn/beta:0. Weight expects shape (480,). Received saved weight with shape (576,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #194 (named block5a_expand_bn) due to mismatch in shape for weight block5a_expand_bn/beta:0. Weight expects shape (480,). Received saved weight with shape (576,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #194 (named block5a_expand_bn) due to mismatch in shape for weight block5a_expand_bn/moving_mean:0. Weight expects shape (480,). Received saved weight with shape (576,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #194 (named block5a_expand_bn) due to mismatch in shape for weight block5a_expand_bn/moving_mean:0. Weight expects shape (480,). Received saved weight with shape (576,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #194 (named block5a_expand_bn) due to mismatch in shape for weight block5a_expand_bn/moving_variance:0. Weight expects shape (480,). Received saved weight with shape (576,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #194 (named block5a_expand_bn) due to mismatch in shape for weight block5a_expand_bn/moving_variance:0. Weight expects shape (480,). Received saved weight with shape (576,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #196 (named block5a_dwconv) due to mismatch in shape for weight block5a_dwconv/depthwise_kernel:0. Weight expects shape (5, 5, 480, 1). Received saved weight with shape (5, 5, 576, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #196 (named block5a_dwconv) due to mismatch in shape for weight block5a_dwconv/depthwise_kernel:0. Weight expects shape (5, 5, 480, 1). Received saved weight with shape (5, 5, 576, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #197 (named block5a_bn) due to mismatch in shape for weight block5a_bn/gamma:0. Weight expects shape (480,). Received saved weight with shape (576,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #197 (named block5a_bn) due to mismatch in shape for weight block5a_bn/gamma:0. Weight expects shape (480,). Received saved weight with shape (576,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #197 (named block5a_bn) due to mismatch in shape for weight block5a_bn/beta:0. Weight expects shape (480,). Received saved weight with shape (576,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #197 (named block5a_bn) due to mismatch in shape for weight block5a_bn/beta:0. Weight expects shape (480,). Received saved weight with shape (576,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #197 (named block5a_bn) due to mismatch in shape for weight block5a_bn/moving_mean:0. Weight expects shape (480,). Received saved weight with shape (576,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #197 (named block5a_bn) due to mismatch in shape for weight block5a_bn/moving_mean:0. Weight expects shape (480,). Received saved weight with shape (576,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #197 (named block5a_bn) due to mismatch in shape for weight block5a_bn/moving_variance:0. Weight expects shape (480,). Received saved weight with shape (576,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #197 (named block5a_bn) due to mismatch in shape for weight block5a_bn/moving_variance:0. Weight expects shape (480,). Received saved weight with shape (576,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #201 (named block5a_se_reduce) due to mismatch in shape for weight block5a_se_reduce/kernel:0. Weight expects shape (1, 1, 480, 20). Received saved weight with shape (24, 576, 1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #201 (named block5a_se_reduce) due to mismatch in shape for weight block5a_se_reduce/kernel:0. Weight expects shape (1, 1, 480, 20). Received saved weight with shape (24, 576, 1, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #201 (named block5a_se_reduce) due to mismatch in shape for weight block5a_se_reduce/bias:0. Weight expects shape (20,). Received saved weight with shape (24,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #201 (named block5a_se_reduce) due to mismatch in shape for weight block5a_se_reduce/bias:0. Weight expects shape (20,). Received saved weight with shape (24,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #202 (named block5a_se_expand) due to mismatch in shape for weight block5a_se_expand/kernel:0. Weight expects shape (1, 1, 20, 480). Received saved weight with shape (576, 24, 1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #202 (named block5a_se_expand) due to mismatch in shape for weight block5a_se_expand/kernel:0. Weight expects shape (1, 1, 20, 480). Received saved weight with shape (576, 24, 1, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #202 (named block5a_se_expand) due to mismatch in shape for weight block5a_se_expand/bias:0. Weight expects shape (480,). Received saved weight with shape (576,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #202 (named block5a_se_expand) due to mismatch in shape for weight block5a_se_expand/bias:0. Weight expects shape (480,). Received saved weight with shape (576,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #204 (named block5a_project_conv) due to mismatch in shape for weight block5a_project_conv/kernel:0. Weight expects shape (1, 1, 480, 112). Received saved weight with shape (136, 576, 1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #204 (named block5a_project_conv) due to mismatch in shape for weight block5a_project_conv/kernel:0. Weight expects shape (1, 1, 480, 112). Received saved weight with shape (136, 576, 1, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #205 (named block5a_project_bn) due to mismatch in shape for weight block5a_project_bn/gamma:0. Weight expects shape (112,). Received saved weight with shape (136,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #205 (named block5a_project_bn) due to mismatch in shape for weight block5a_project_bn/gamma:0. Weight expects shape (112,). Received saved weight with shape (136,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #205 (named block5a_project_bn) due to mismatch in shape for weight block5a_project_bn/beta:0. Weight expects shape (112,). Received saved weight with shape (136,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #205 (named block5a_project_bn) due to mismatch in shape for weight block5a_project_bn/beta:0. Weight expects shape (112,). Received saved weight with shape (136,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #205 (named block5a_project_bn) due to mismatch in shape for weight block5a_project_bn/moving_mean:0. Weight expects shape (112,). Received saved weight with shape (136,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #205 (named block5a_project_bn) due to mismatch in shape for weight block5a_project_bn/moving_mean:0. Weight expects shape (112,). Received saved weight with shape (136,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #205 (named block5a_project_bn) due to mismatch in shape for weight block5a_project_bn/moving_variance:0. Weight expects shape (112,). Received saved weight with shape (136,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #205 (named block5a_project_bn) due to mismatch in shape for weight block5a_project_bn/moving_variance:0. Weight expects shape (112,). Received saved weight with shape (136,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #206 (named block5b_expand_conv) due to mismatch in shape for weight block5b_expand_conv/kernel:0. Weight expects shape (1, 1, 112, 672). Received saved weight with shape (816, 136, 1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #206 (named block5b_expand_conv) due to mismatch in shape for weight block5b_expand_conv/kernel:0. Weight expects shape (1, 1, 112, 672). Received saved weight with shape (816, 136, 1, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #207 (named block5b_expand_bn) due to mismatch in shape for weight block5b_expand_bn/gamma:0. Weight expects shape (672,). Received saved weight with shape (816,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #207 (named block5b_expand_bn) due to mismatch in shape for weight block5b_expand_bn/gamma:0. Weight expects shape (672,). Received saved weight with shape (816,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #207 (named block5b_expand_bn) due to mismatch in shape for weight block5b_expand_bn/beta:0. Weight expects shape (672,). Received saved weight with shape (816,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #207 (named block5b_expand_bn) due to mismatch in shape for weight block5b_expand_bn/beta:0. Weight expects shape (672,). Received saved weight with shape (816,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #207 (named block5b_expand_bn) due to mismatch in shape for weight block5b_expand_bn/moving_mean:0. Weight expects shape (672,). Received saved weight with shape (816,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #207 (named block5b_expand_bn) due to mismatch in shape for weight block5b_expand_bn/moving_mean:0. Weight expects shape (672,). Received saved weight with shape (816,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #207 (named block5b_expand_bn) due to mismatch in shape for weight block5b_expand_bn/moving_variance:0. Weight expects shape (672,). Received saved weight with shape (816,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #207 (named block5b_expand_bn) due to mismatch in shape for weight block5b_expand_bn/moving_variance:0. Weight expects shape (672,). Received saved weight with shape (816,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #209 (named block5b_dwconv) due to mismatch in shape for weight block5b_dwconv/depthwise_kernel:0. Weight expects shape (5, 5, 672, 1). Received saved weight with shape (5, 5, 816, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #209 (named block5b_dwconv) due to mismatch in shape for weight block5b_dwconv/depthwise_kernel:0. Weight expects shape (5, 5, 672, 1). Received saved weight with shape (5, 5, 816, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #210 (named block5b_bn) due to mismatch in shape for weight block5b_bn/gamma:0. Weight expects shape (672,). Received saved weight with shape (816,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #210 (named block5b_bn) due to mismatch in shape for weight block5b_bn/gamma:0. Weight expects shape (672,). Received saved weight with shape (816,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #210 (named block5b_bn) due to mismatch in shape for weight block5b_bn/beta:0. Weight expects shape (672,). Received saved weight with shape (816,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #210 (named block5b_bn) due to mismatch in shape for weight block5b_bn/beta:0. Weight expects shape (672,). Received saved weight with shape (816,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #210 (named block5b_bn) due to mismatch in shape for weight block5b_bn/moving_mean:0. Weight expects shape (672,). Received saved weight with shape (816,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #210 (named block5b_bn) due to mismatch in shape for weight block5b_bn/moving_mean:0. Weight expects shape (672,). Received saved weight with shape (816,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #210 (named block5b_bn) due to mismatch in shape for weight block5b_bn/moving_variance:0. Weight expects shape (672,). Received saved weight with shape (816,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #210 (named block5b_bn) due to mismatch in shape for weight block5b_bn/moving_variance:0. Weight expects shape (672,). Received saved weight with shape (816,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #214 (named block5b_se_reduce) due to mismatch in shape for weight block5b_se_reduce/kernel:0. Weight expects shape (1, 1, 672, 28). Received saved weight with shape (34, 816, 1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #214 (named block5b_se_reduce) due to mismatch in shape for weight block5b_se_reduce/kernel:0. Weight expects shape (1, 1, 672, 28). Received saved weight with shape (34, 816, 1, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #214 (named block5b_se_reduce) due to mismatch in shape for weight block5b_se_reduce/bias:0. Weight expects shape (28,). Received saved weight with shape (34,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #214 (named block5b_se_reduce) due to mismatch in shape for weight block5b_se_reduce/bias:0. Weight expects shape (28,). Received saved weight with shape (34,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #215 (named block5b_se_expand) due to mismatch in shape for weight block5b_se_expand/kernel:0. Weight expects shape (1, 1, 28, 672). Received saved weight with shape (816, 34, 1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #215 (named block5b_se_expand) due to mismatch in shape for weight block5b_se_expand/kernel:0. Weight expects shape (1, 1, 28, 672). Received saved weight with shape (816, 34, 1, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #215 (named block5b_se_expand) due to mismatch in shape for weight block5b_se_expand/bias:0. Weight expects shape (672,). Received saved weight with shape (816,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #215 (named block5b_se_expand) due to mismatch in shape for weight block5b_se_expand/bias:0. Weight expects shape (672,). Received saved weight with shape (816,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #217 (named block5b_project_conv) due to mismatch in shape for weight block5b_project_conv/kernel:0. Weight expects shape (1, 1, 672, 112). Received saved weight with shape (136, 816, 1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #217 (named block5b_project_conv) due to mismatch in shape for weight block5b_project_conv/kernel:0. Weight expects shape (1, 1, 672, 112). Received saved weight with shape (136, 816, 1, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #218 (named block5b_project_bn) due to mismatch in shape for weight block5b_project_bn/gamma:0. Weight expects shape (112,). Received saved weight with shape (136,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #218 (named block5b_project_bn) due to mismatch in shape for weight block5b_project_bn/gamma:0. Weight expects shape (112,). Received saved weight with shape (136,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #218 (named block5b_project_bn) due to mismatch in shape for weight block5b_project_bn/beta:0. Weight expects shape (112,). Received saved weight with shape (136,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #218 (named block5b_project_bn) due to mismatch in shape for weight block5b_project_bn/beta:0. Weight expects shape (112,). Received saved weight with shape (136,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #218 (named block5b_project_bn) due to mismatch in shape for weight block5b_project_bn/moving_mean:0. Weight expects shape (112,). Received saved weight with shape (136,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #218 (named block5b_project_bn) due to mismatch in shape for weight block5b_project_bn/moving_mean:0. Weight expects shape (112,). Received saved weight with shape (136,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #218 (named block5b_project_bn) due to mismatch in shape for weight block5b_project_bn/moving_variance:0. Weight expects shape (112,). Received saved weight with shape (136,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #218 (named block5b_project_bn) due to mismatch in shape for weight block5b_project_bn/moving_variance:0. Weight expects shape (112,). Received saved weight with shape (136,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #221 (named block5c_expand_conv) due to mismatch in shape for weight block5c_expand_conv/kernel:0. Weight expects shape (1, 1, 112, 672). Received saved weight with shape (816, 136, 1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #221 (named block5c_expand_conv) due to mismatch in shape for weight block5c_expand_conv/kernel:0. Weight expects shape (1, 1, 112, 672). Received saved weight with shape (816, 136, 1, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #222 (named block5c_expand_bn) due to mismatch in shape for weight block5c_expand_bn/gamma:0. Weight expects shape (672,). Received saved weight with shape (816,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #222 (named block5c_expand_bn) due to mismatch in shape for weight block5c_expand_bn/gamma:0. Weight expects shape (672,). Received saved weight with shape (816,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #222 (named block5c_expand_bn) due to mismatch in shape for weight block5c_expand_bn/beta:0. Weight expects shape (672,). Received saved weight with shape (816,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #222 (named block5c_expand_bn) due to mismatch in shape for weight block5c_expand_bn/beta:0. Weight expects shape (672,). Received saved weight with shape (816,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #222 (named block5c_expand_bn) due to mismatch in shape for weight block5c_expand_bn/moving_mean:0. Weight expects shape (672,). Received saved weight with shape (816,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #222 (named block5c_expand_bn) due to mismatch in shape for weight block5c_expand_bn/moving_mean:0. Weight expects shape (672,). Received saved weight with shape (816,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #222 (named block5c_expand_bn) due to mismatch in shape for weight block5c_expand_bn/moving_variance:0. Weight expects shape (672,). Received saved weight with shape (816,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #222 (named block5c_expand_bn) due to mismatch in shape for weight block5c_expand_bn/moving_variance:0. Weight expects shape (672,). Received saved weight with shape (816,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #224 (named block5c_dwconv) due to mismatch in shape for weight block5c_dwconv/depthwise_kernel:0. Weight expects shape (5, 5, 672, 1). Received saved weight with shape (5, 5, 816, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #224 (named block5c_dwconv) due to mismatch in shape for weight block5c_dwconv/depthwise_kernel:0. Weight expects shape (5, 5, 672, 1). Received saved weight with shape (5, 5, 816, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #225 (named block5c_bn) due to mismatch in shape for weight block5c_bn/gamma:0. Weight expects shape (672,). Received saved weight with shape (816,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #225 (named block5c_bn) due to mismatch in shape for weight block5c_bn/gamma:0. Weight expects shape (672,). Received saved weight with shape (816,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #225 (named block5c_bn) due to mismatch in shape for weight block5c_bn/beta:0. Weight expects shape (672,). Received saved weight with shape (816,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #225 (named block5c_bn) due to mismatch in shape for weight block5c_bn/beta:0. Weight expects shape (672,). Received saved weight with shape (816,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #225 (named block5c_bn) due to mismatch in shape for weight block5c_bn/moving_mean:0. Weight expects shape (672,). Received saved weight with shape (816,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #225 (named block5c_bn) due to mismatch in shape for weight block5c_bn/moving_mean:0. Weight expects shape (672,). Received saved weight with shape (816,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #225 (named block5c_bn) due to mismatch in shape for weight block5c_bn/moving_variance:0. Weight expects shape (672,). Received saved weight with shape (816,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #225 (named block5c_bn) due to mismatch in shape for weight block5c_bn/moving_variance:0. Weight expects shape (672,). Received saved weight with shape (816,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #229 (named block5c_se_reduce) due to mismatch in shape for weight block5c_se_reduce/kernel:0. Weight expects shape (1, 1, 672, 28). Received saved weight with shape (34, 816, 1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #229 (named block5c_se_reduce) due to mismatch in shape for weight block5c_se_reduce/kernel:0. Weight expects shape (1, 1, 672, 28). Received saved weight with shape (34, 816, 1, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #229 (named block5c_se_reduce) due to mismatch in shape for weight block5c_se_reduce/bias:0. Weight expects shape (28,). Received saved weight with shape (34,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #229 (named block5c_se_reduce) due to mismatch in shape for weight block5c_se_reduce/bias:0. Weight expects shape (28,). Received saved weight with shape (34,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #230 (named block5c_se_expand) due to mismatch in shape for weight block5c_se_expand/kernel:0. Weight expects shape (1, 1, 28, 672). Received saved weight with shape (816, 34, 1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #230 (named block5c_se_expand) due to mismatch in shape for weight block5c_se_expand/kernel:0. Weight expects shape (1, 1, 28, 672). Received saved weight with shape (816, 34, 1, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #230 (named block5c_se_expand) due to mismatch in shape for weight block5c_se_expand/bias:0. Weight expects shape (672,). Received saved weight with shape (816,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #230 (named block5c_se_expand) due to mismatch in shape for weight block5c_se_expand/bias:0. Weight expects shape (672,). Received saved weight with shape (816,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #232 (named block5c_project_conv) due to mismatch in shape for weight block5c_project_conv/kernel:0. Weight expects shape (1, 1, 672, 112). Received saved weight with shape (136, 816, 1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #232 (named block5c_project_conv) due to mismatch in shape for weight block5c_project_conv/kernel:0. Weight expects shape (1, 1, 672, 112). Received saved weight with shape (136, 816, 1, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #233 (named block5c_project_bn) due to mismatch in shape for weight block5c_project_bn/gamma:0. Weight expects shape (112,). Received saved weight with shape (136,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #233 (named block5c_project_bn) due to mismatch in shape for weight block5c_project_bn/gamma:0. Weight expects shape (112,). Received saved weight with shape (136,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #233 (named block5c_project_bn) due to mismatch in shape for weight block5c_project_bn/beta:0. Weight expects shape (112,). Received saved weight with shape (136,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #233 (named block5c_project_bn) due to mismatch in shape for weight block5c_project_bn/beta:0. Weight expects shape (112,). Received saved weight with shape (136,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #233 (named block5c_project_bn) due to mismatch in shape for weight block5c_project_bn/moving_mean:0. Weight expects shape (112,). Received saved weight with shape (136,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #233 (named block5c_project_bn) due to mismatch in shape for weight block5c_project_bn/moving_mean:0. Weight expects shape (112,). Received saved weight with shape (136,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #233 (named block5c_project_bn) due to mismatch in shape for weight block5c_project_bn/moving_variance:0. Weight expects shape (112,). Received saved weight with shape (136,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #233 (named block5c_project_bn) due to mismatch in shape for weight block5c_project_bn/moving_variance:0. Weight expects shape (112,). Received saved weight with shape (136,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #266 (named block6a_expand_conv) due to mismatch in shape for weight block6a_expand_conv/kernel:0. Weight expects shape (1, 1, 112, 672). Received saved weight with shape (816, 136, 1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #266 (named block6a_expand_conv) due to mismatch in shape for weight block6a_expand_conv/kernel:0. Weight expects shape (1, 1, 112, 672). Received saved weight with shape (816, 136, 1, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #267 (named block6a_expand_bn) due to mismatch in shape for weight block6a_expand_bn/gamma:0. Weight expects shape (672,). Received saved weight with shape (816,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #267 (named block6a_expand_bn) due to mismatch in shape for weight block6a_expand_bn/gamma:0. Weight expects shape (672,). Received saved weight with shape (816,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #267 (named block6a_expand_bn) due to mismatch in shape for weight block6a_expand_bn/beta:0. Weight expects shape (672,). Received saved weight with shape (816,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #267 (named block6a_expand_bn) due to mismatch in shape for weight block6a_expand_bn/beta:0. Weight expects shape (672,). Received saved weight with shape (816,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #267 (named block6a_expand_bn) due to mismatch in shape for weight block6a_expand_bn/moving_mean:0. Weight expects shape (672,). Received saved weight with shape (816,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #267 (named block6a_expand_bn) due to mismatch in shape for weight block6a_expand_bn/moving_mean:0. Weight expects shape (672,). Received saved weight with shape (816,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #267 (named block6a_expand_bn) due to mismatch in shape for weight block6a_expand_bn/moving_variance:0. Weight expects shape (672,). Received saved weight with shape (816,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #267 (named block6a_expand_bn) due to mismatch in shape for weight block6a_expand_bn/moving_variance:0. Weight expects shape (672,). Received saved weight with shape (816,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #270 (named block6a_dwconv) due to mismatch in shape for weight block6a_dwconv/depthwise_kernel:0. Weight expects shape (5, 5, 672, 1). Received saved weight with shape (5, 5, 816, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #270 (named block6a_dwconv) due to mismatch in shape for weight block6a_dwconv/depthwise_kernel:0. Weight expects shape (5, 5, 672, 1). Received saved weight with shape (5, 5, 816, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #271 (named block6a_bn) due to mismatch in shape for weight block6a_bn/gamma:0. Weight expects shape (672,). Received saved weight with shape (816,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #271 (named block6a_bn) due to mismatch in shape for weight block6a_bn/gamma:0. Weight expects shape (672,). Received saved weight with shape (816,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #271 (named block6a_bn) due to mismatch in shape for weight block6a_bn/beta:0. Weight expects shape (672,). Received saved weight with shape (816,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #271 (named block6a_bn) due to mismatch in shape for weight block6a_bn/beta:0. Weight expects shape (672,). Received saved weight with shape (816,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #271 (named block6a_bn) due to mismatch in shape for weight block6a_bn/moving_mean:0. Weight expects shape (672,). Received saved weight with shape (816,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #271 (named block6a_bn) due to mismatch in shape for weight block6a_bn/moving_mean:0. Weight expects shape (672,). Received saved weight with shape (816,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #271 (named block6a_bn) due to mismatch in shape for weight block6a_bn/moving_variance:0. Weight expects shape (672,). Received saved weight with shape (816,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #271 (named block6a_bn) due to mismatch in shape for weight block6a_bn/moving_variance:0. Weight expects shape (672,). Received saved weight with shape (816,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #275 (named block6a_se_reduce) due to mismatch in shape for weight block6a_se_reduce/kernel:0. Weight expects shape (1, 1, 672, 28). Received saved weight with shape (34, 816, 1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #275 (named block6a_se_reduce) due to mismatch in shape for weight block6a_se_reduce/kernel:0. Weight expects shape (1, 1, 672, 28). Received saved weight with shape (34, 816, 1, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #275 (named block6a_se_reduce) due to mismatch in shape for weight block6a_se_reduce/bias:0. Weight expects shape (28,). Received saved weight with shape (34,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #275 (named block6a_se_reduce) due to mismatch in shape for weight block6a_se_reduce/bias:0. Weight expects shape (28,). Received saved weight with shape (34,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #276 (named block6a_se_expand) due to mismatch in shape for weight block6a_se_expand/kernel:0. Weight expects shape (1, 1, 28, 672). Received saved weight with shape (816, 34, 1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #276 (named block6a_se_expand) due to mismatch in shape for weight block6a_se_expand/kernel:0. Weight expects shape (1, 1, 28, 672). Received saved weight with shape (816, 34, 1, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #276 (named block6a_se_expand) due to mismatch in shape for weight block6a_se_expand/bias:0. Weight expects shape (672,). Received saved weight with shape (816,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #276 (named block6a_se_expand) due to mismatch in shape for weight block6a_se_expand/bias:0. Weight expects shape (672,). Received saved weight with shape (816,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #278 (named block6a_project_conv) due to mismatch in shape for weight block6a_project_conv/kernel:0. Weight expects shape (1, 1, 672, 192). Received saved weight with shape (232, 816, 1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #278 (named block6a_project_conv) due to mismatch in shape for weight block6a_project_conv/kernel:0. Weight expects shape (1, 1, 672, 192). Received saved weight with shape (232, 816, 1, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #279 (named block6a_project_bn) due to mismatch in shape for weight block6a_project_bn/gamma:0. Weight expects shape (192,). Received saved weight with shape (232,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #279 (named block6a_project_bn) due to mismatch in shape for weight block6a_project_bn/gamma:0. Weight expects shape (192,). Received saved weight with shape (232,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #279 (named block6a_project_bn) due to mismatch in shape for weight block6a_project_bn/beta:0. Weight expects shape (192,). Received saved weight with shape (232,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #279 (named block6a_project_bn) due to mismatch in shape for weight block6a_project_bn/beta:0. Weight expects shape (192,). Received saved weight with shape (232,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #279 (named block6a_project_bn) due to mismatch in shape for weight block6a_project_bn/moving_mean:0. Weight expects shape (192,). Received saved weight with shape (232,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #279 (named block6a_project_bn) due to mismatch in shape for weight block6a_project_bn/moving_mean:0. Weight expects shape (192,). Received saved weight with shape (232,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #279 (named block6a_project_bn) due to mismatch in shape for weight block6a_project_bn/moving_variance:0. Weight expects shape (192,). Received saved weight with shape (232,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #279 (named block6a_project_bn) due to mismatch in shape for weight block6a_project_bn/moving_variance:0. Weight expects shape (192,). Received saved weight with shape (232,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #280 (named block6b_expand_conv) due to mismatch in shape for weight block6b_expand_conv/kernel:0. Weight expects shape (1, 1, 192, 1152). Received saved weight with shape (1392, 232, 1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #280 (named block6b_expand_conv) due to mismatch in shape for weight block6b_expand_conv/kernel:0. Weight expects shape (1, 1, 192, 1152). Received saved weight with shape (1392, 232, 1, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #281 (named block6b_expand_bn) due to mismatch in shape for weight block6b_expand_bn/gamma:0. Weight expects shape (1152,). Received saved weight with shape (1392,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #281 (named block6b_expand_bn) due to mismatch in shape for weight block6b_expand_bn/gamma:0. Weight expects shape (1152,). Received saved weight with shape (1392,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #281 (named block6b_expand_bn) due to mismatch in shape for weight block6b_expand_bn/beta:0. Weight expects shape (1152,). Received saved weight with shape (1392,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #281 (named block6b_expand_bn) due to mismatch in shape for weight block6b_expand_bn/beta:0. Weight expects shape (1152,). Received saved weight with shape (1392,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #281 (named block6b_expand_bn) due to mismatch in shape for weight block6b_expand_bn/moving_mean:0. Weight expects shape (1152,). Received saved weight with shape (1392,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #281 (named block6b_expand_bn) due to mismatch in shape for weight block6b_expand_bn/moving_mean:0. Weight expects shape (1152,). Received saved weight with shape (1392,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #281 (named block6b_expand_bn) due to mismatch in shape for weight block6b_expand_bn/moving_variance:0. Weight expects shape (1152,). Received saved weight with shape (1392,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #281 (named block6b_expand_bn) due to mismatch in shape for weight block6b_expand_bn/moving_variance:0. Weight expects shape (1152,). Received saved weight with shape (1392,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #283 (named block6b_dwconv) due to mismatch in shape for weight block6b_dwconv/depthwise_kernel:0. Weight expects shape (5, 5, 1152, 1). Received saved weight with shape (5, 5, 1392, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #283 (named block6b_dwconv) due to mismatch in shape for weight block6b_dwconv/depthwise_kernel:0. Weight expects shape (5, 5, 1152, 1). Received saved weight with shape (5, 5, 1392, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #284 (named block6b_bn) due to mismatch in shape for weight block6b_bn/gamma:0. Weight expects shape (1152,). Received saved weight with shape (1392,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #284 (named block6b_bn) due to mismatch in shape for weight block6b_bn/gamma:0. Weight expects shape (1152,). Received saved weight with shape (1392,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #284 (named block6b_bn) due to mismatch in shape for weight block6b_bn/beta:0. Weight expects shape (1152,). Received saved weight with shape (1392,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #284 (named block6b_bn) due to mismatch in shape for weight block6b_bn/beta:0. Weight expects shape (1152,). Received saved weight with shape (1392,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #284 (named block6b_bn) due to mismatch in shape for weight block6b_bn/moving_mean:0. Weight expects shape (1152,). Received saved weight with shape (1392,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #284 (named block6b_bn) due to mismatch in shape for weight block6b_bn/moving_mean:0. Weight expects shape (1152,). Received saved weight with shape (1392,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #284 (named block6b_bn) due to mismatch in shape for weight block6b_bn/moving_variance:0. Weight expects shape (1152,). Received saved weight with shape (1392,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #284 (named block6b_bn) due to mismatch in shape for weight block6b_bn/moving_variance:0. Weight expects shape (1152,). Received saved weight with shape (1392,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #288 (named block6b_se_reduce) due to mismatch in shape for weight block6b_se_reduce/kernel:0. Weight expects shape (1, 1, 1152, 48). Received saved weight with shape (58, 1392, 1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #288 (named block6b_se_reduce) due to mismatch in shape for weight block6b_se_reduce/kernel:0. Weight expects shape (1, 1, 1152, 48). Received saved weight with shape (58, 1392, 1, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #288 (named block6b_se_reduce) due to mismatch in shape for weight block6b_se_reduce/bias:0. Weight expects shape (48,). Received saved weight with shape (58,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #288 (named block6b_se_reduce) due to mismatch in shape for weight block6b_se_reduce/bias:0. Weight expects shape (48,). Received saved weight with shape (58,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #289 (named block6b_se_expand) due to mismatch in shape for weight block6b_se_expand/kernel:0. Weight expects shape (1, 1, 48, 1152). Received saved weight with shape (1392, 58, 1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #289 (named block6b_se_expand) due to mismatch in shape for weight block6b_se_expand/kernel:0. Weight expects shape (1, 1, 48, 1152). Received saved weight with shape (1392, 58, 1, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #289 (named block6b_se_expand) due to mismatch in shape for weight block6b_se_expand/bias:0. Weight expects shape (1152,). Received saved weight with shape (1392,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #289 (named block6b_se_expand) due to mismatch in shape for weight block6b_se_expand/bias:0. Weight expects shape (1152,). Received saved weight with shape (1392,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #291 (named block6b_project_conv) due to mismatch in shape for weight block6b_project_conv/kernel:0. Weight expects shape (1, 1, 1152, 192). Received saved weight with shape (232, 1392, 1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #291 (named block6b_project_conv) due to mismatch in shape for weight block6b_project_conv/kernel:0. Weight expects shape (1, 1, 1152, 192). Received saved weight with shape (232, 1392, 1, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #292 (named block6b_project_bn) due to mismatch in shape for weight block6b_project_bn/gamma:0. Weight expects shape (192,). Received saved weight with shape (232,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #292 (named block6b_project_bn) due to mismatch in shape for weight block6b_project_bn/gamma:0. Weight expects shape (192,). Received saved weight with shape (232,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #292 (named block6b_project_bn) due to mismatch in shape for weight block6b_project_bn/beta:0. Weight expects shape (192,). Received saved weight with shape (232,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #292 (named block6b_project_bn) due to mismatch in shape for weight block6b_project_bn/beta:0. Weight expects shape (192,). Received saved weight with shape (232,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #292 (named block6b_project_bn) due to mismatch in shape for weight block6b_project_bn/moving_mean:0. Weight expects shape (192,). Received saved weight with shape (232,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #292 (named block6b_project_bn) due to mismatch in shape for weight block6b_project_bn/moving_mean:0. Weight expects shape (192,). Received saved weight with shape (232,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #292 (named block6b_project_bn) due to mismatch in shape for weight block6b_project_bn/moving_variance:0. Weight expects shape (192,). Received saved weight with shape (232,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #292 (named block6b_project_bn) due to mismatch in shape for weight block6b_project_bn/moving_variance:0. Weight expects shape (192,). Received saved weight with shape (232,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #295 (named block6c_expand_conv) due to mismatch in shape for weight block6c_expand_conv/kernel:0. Weight expects shape (1, 1, 192, 1152). Received saved weight with shape (1392, 232, 1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #295 (named block6c_expand_conv) due to mismatch in shape for weight block6c_expand_conv/kernel:0. Weight expects shape (1, 1, 192, 1152). Received saved weight with shape (1392, 232, 1, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #296 (named block6c_expand_bn) due to mismatch in shape for weight block6c_expand_bn/gamma:0. Weight expects shape (1152,). Received saved weight with shape (1392,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #296 (named block6c_expand_bn) due to mismatch in shape for weight block6c_expand_bn/gamma:0. Weight expects shape (1152,). Received saved weight with shape (1392,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #296 (named block6c_expand_bn) due to mismatch in shape for weight block6c_expand_bn/beta:0. Weight expects shape (1152,). Received saved weight with shape (1392,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #296 (named block6c_expand_bn) due to mismatch in shape for weight block6c_expand_bn/beta:0. Weight expects shape (1152,). Received saved weight with shape (1392,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #296 (named block6c_expand_bn) due to mismatch in shape for weight block6c_expand_bn/moving_mean:0. Weight expects shape (1152,). Received saved weight with shape (1392,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #296 (named block6c_expand_bn) due to mismatch in shape for weight block6c_expand_bn/moving_mean:0. Weight expects shape (1152,). Received saved weight with shape (1392,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #296 (named block6c_expand_bn) due to mismatch in shape for weight block6c_expand_bn/moving_variance:0. Weight expects shape (1152,). Received saved weight with shape (1392,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #296 (named block6c_expand_bn) due to mismatch in shape for weight block6c_expand_bn/moving_variance:0. Weight expects shape (1152,). Received saved weight with shape (1392,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #298 (named block6c_dwconv) due to mismatch in shape for weight block6c_dwconv/depthwise_kernel:0. Weight expects shape (5, 5, 1152, 1). Received saved weight with shape (5, 5, 1392, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #298 (named block6c_dwconv) due to mismatch in shape for weight block6c_dwconv/depthwise_kernel:0. Weight expects shape (5, 5, 1152, 1). Received saved weight with shape (5, 5, 1392, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #299 (named block6c_bn) due to mismatch in shape for weight block6c_bn/gamma:0. Weight expects shape (1152,). Received saved weight with shape (1392,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #299 (named block6c_bn) due to mismatch in shape for weight block6c_bn/gamma:0. Weight expects shape (1152,). Received saved weight with shape (1392,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #299 (named block6c_bn) due to mismatch in shape for weight block6c_bn/beta:0. Weight expects shape (1152,). Received saved weight with shape (1392,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #299 (named block6c_bn) due to mismatch in shape for weight block6c_bn/beta:0. Weight expects shape (1152,). Received saved weight with shape (1392,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #299 (named block6c_bn) due to mismatch in shape for weight block6c_bn/moving_mean:0. Weight expects shape (1152,). Received saved weight with shape (1392,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #299 (named block6c_bn) due to mismatch in shape for weight block6c_bn/moving_mean:0. Weight expects shape (1152,). Received saved weight with shape (1392,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #299 (named block6c_bn) due to mismatch in shape for weight block6c_bn/moving_variance:0. Weight expects shape (1152,). Received saved weight with shape (1392,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #299 (named block6c_bn) due to mismatch in shape for weight block6c_bn/moving_variance:0. Weight expects shape (1152,). Received saved weight with shape (1392,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #303 (named block6c_se_reduce) due to mismatch in shape for weight block6c_se_reduce/kernel:0. Weight expects shape (1, 1, 1152, 48). Received saved weight with shape (58, 1392, 1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #303 (named block6c_se_reduce) due to mismatch in shape for weight block6c_se_reduce/kernel:0. Weight expects shape (1, 1, 1152, 48). Received saved weight with shape (58, 1392, 1, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #303 (named block6c_se_reduce) due to mismatch in shape for weight block6c_se_reduce/bias:0. Weight expects shape (48,). Received saved weight with shape (58,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #303 (named block6c_se_reduce) due to mismatch in shape for weight block6c_se_reduce/bias:0. Weight expects shape (48,). Received saved weight with shape (58,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #304 (named block6c_se_expand) due to mismatch in shape for weight block6c_se_expand/kernel:0. Weight expects shape (1, 1, 48, 1152). Received saved weight with shape (1392, 58, 1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #304 (named block6c_se_expand) due to mismatch in shape for weight block6c_se_expand/kernel:0. Weight expects shape (1, 1, 48, 1152). Received saved weight with shape (1392, 58, 1, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #304 (named block6c_se_expand) due to mismatch in shape for weight block6c_se_expand/bias:0. Weight expects shape (1152,). Received saved weight with shape (1392,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #304 (named block6c_se_expand) due to mismatch in shape for weight block6c_se_expand/bias:0. Weight expects shape (1152,). Received saved weight with shape (1392,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #306 (named block6c_project_conv) due to mismatch in shape for weight block6c_project_conv/kernel:0. Weight expects shape (1, 1, 1152, 192). Received saved weight with shape (232, 1392, 1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #306 (named block6c_project_conv) due to mismatch in shape for weight block6c_project_conv/kernel:0. Weight expects shape (1, 1, 1152, 192). Received saved weight with shape (232, 1392, 1, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #307 (named block6c_project_bn) due to mismatch in shape for weight block6c_project_bn/gamma:0. Weight expects shape (192,). Received saved weight with shape (232,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #307 (named block6c_project_bn) due to mismatch in shape for weight block6c_project_bn/gamma:0. Weight expects shape (192,). Received saved weight with shape (232,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #307 (named block6c_project_bn) due to mismatch in shape for weight block6c_project_bn/beta:0. Weight expects shape (192,). Received saved weight with shape (232,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #307 (named block6c_project_bn) due to mismatch in shape for weight block6c_project_bn/beta:0. Weight expects shape (192,). Received saved weight with shape (232,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #307 (named block6c_project_bn) due to mismatch in shape for weight block6c_project_bn/moving_mean:0. Weight expects shape (192,). Received saved weight with shape (232,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #307 (named block6c_project_bn) due to mismatch in shape for weight block6c_project_bn/moving_mean:0. Weight expects shape (192,). Received saved weight with shape (232,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #307 (named block6c_project_bn) due to mismatch in shape for weight block6c_project_bn/moving_variance:0. Weight expects shape (192,). Received saved weight with shape (232,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #307 (named block6c_project_bn) due to mismatch in shape for weight block6c_project_bn/moving_variance:0. Weight expects shape (192,). Received saved weight with shape (232,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #310 (named block6d_expand_conv) due to mismatch in shape for weight block6d_expand_conv/kernel:0. Weight expects shape (1, 1, 192, 1152). Received saved weight with shape (1392, 232, 1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #310 (named block6d_expand_conv) due to mismatch in shape for weight block6d_expand_conv/kernel:0. Weight expects shape (1, 1, 192, 1152). Received saved weight with shape (1392, 232, 1, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #311 (named block6d_expand_bn) due to mismatch in shape for weight block6d_expand_bn/gamma:0. Weight expects shape (1152,). Received saved weight with shape (1392,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #311 (named block6d_expand_bn) due to mismatch in shape for weight block6d_expand_bn/gamma:0. Weight expects shape (1152,). Received saved weight with shape (1392,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #311 (named block6d_expand_bn) due to mismatch in shape for weight block6d_expand_bn/beta:0. Weight expects shape (1152,). Received saved weight with shape (1392,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #311 (named block6d_expand_bn) due to mismatch in shape for weight block6d_expand_bn/beta:0. Weight expects shape (1152,). Received saved weight with shape (1392,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #311 (named block6d_expand_bn) due to mismatch in shape for weight block6d_expand_bn/moving_mean:0. Weight expects shape (1152,). Received saved weight with shape (1392,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #311 (named block6d_expand_bn) due to mismatch in shape for weight block6d_expand_bn/moving_mean:0. Weight expects shape (1152,). Received saved weight with shape (1392,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #311 (named block6d_expand_bn) due to mismatch in shape for weight block6d_expand_bn/moving_variance:0. Weight expects shape (1152,). Received saved weight with shape (1392,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #311 (named block6d_expand_bn) due to mismatch in shape for weight block6d_expand_bn/moving_variance:0. Weight expects shape (1152,). Received saved weight with shape (1392,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #313 (named block6d_dwconv) due to mismatch in shape for weight block6d_dwconv/depthwise_kernel:0. Weight expects shape (5, 5, 1152, 1). Received saved weight with shape (5, 5, 1392, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #313 (named block6d_dwconv) due to mismatch in shape for weight block6d_dwconv/depthwise_kernel:0. Weight expects shape (5, 5, 1152, 1). Received saved weight with shape (5, 5, 1392, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #314 (named block6d_bn) due to mismatch in shape for weight block6d_bn/gamma:0. Weight expects shape (1152,). Received saved weight with shape (1392,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #314 (named block6d_bn) due to mismatch in shape for weight block6d_bn/gamma:0. Weight expects shape (1152,). Received saved weight with shape (1392,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #314 (named block6d_bn) due to mismatch in shape for weight block6d_bn/beta:0. Weight expects shape (1152,). Received saved weight with shape (1392,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #314 (named block6d_bn) due to mismatch in shape for weight block6d_bn/beta:0. Weight expects shape (1152,). Received saved weight with shape (1392,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #314 (named block6d_bn) due to mismatch in shape for weight block6d_bn/moving_mean:0. Weight expects shape (1152,). Received saved weight with shape (1392,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #314 (named block6d_bn) due to mismatch in shape for weight block6d_bn/moving_mean:0. Weight expects shape (1152,). Received saved weight with shape (1392,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #314 (named block6d_bn) due to mismatch in shape for weight block6d_bn/moving_variance:0. Weight expects shape (1152,). Received saved weight with shape (1392,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #314 (named block6d_bn) due to mismatch in shape for weight block6d_bn/moving_variance:0. Weight expects shape (1152,). Received saved weight with shape (1392,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #318 (named block6d_se_reduce) due to mismatch in shape for weight block6d_se_reduce/kernel:0. Weight expects shape (1, 1, 1152, 48). Received saved weight with shape (58, 1392, 1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #318 (named block6d_se_reduce) due to mismatch in shape for weight block6d_se_reduce/kernel:0. Weight expects shape (1, 1, 1152, 48). Received saved weight with shape (58, 1392, 1, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #318 (named block6d_se_reduce) due to mismatch in shape for weight block6d_se_reduce/bias:0. Weight expects shape (48,). Received saved weight with shape (58,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #318 (named block6d_se_reduce) due to mismatch in shape for weight block6d_se_reduce/bias:0. Weight expects shape (48,). Received saved weight with shape (58,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #319 (named block6d_se_expand) due to mismatch in shape for weight block6d_se_expand/kernel:0. Weight expects shape (1, 1, 48, 1152). Received saved weight with shape (1392, 58, 1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #319 (named block6d_se_expand) due to mismatch in shape for weight block6d_se_expand/kernel:0. Weight expects shape (1, 1, 48, 1152). Received saved weight with shape (1392, 58, 1, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #319 (named block6d_se_expand) due to mismatch in shape for weight block6d_se_expand/bias:0. Weight expects shape (1152,). Received saved weight with shape (1392,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #319 (named block6d_se_expand) due to mismatch in shape for weight block6d_se_expand/bias:0. Weight expects shape (1152,). Received saved weight with shape (1392,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #321 (named block6d_project_conv) due to mismatch in shape for weight block6d_project_conv/kernel:0. Weight expects shape (1, 1, 1152, 192). Received saved weight with shape (232, 1392, 1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #321 (named block6d_project_conv) due to mismatch in shape for weight block6d_project_conv/kernel:0. Weight expects shape (1, 1, 1152, 192). Received saved weight with shape (232, 1392, 1, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #322 (named block6d_project_bn) due to mismatch in shape for weight block6d_project_bn/gamma:0. Weight expects shape (192,). Received saved weight with shape (232,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #322 (named block6d_project_bn) due to mismatch in shape for weight block6d_project_bn/gamma:0. Weight expects shape (192,). Received saved weight with shape (232,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #322 (named block6d_project_bn) due to mismatch in shape for weight block6d_project_bn/beta:0. Weight expects shape (192,). Received saved weight with shape (232,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #322 (named block6d_project_bn) due to mismatch in shape for weight block6d_project_bn/beta:0. Weight expects shape (192,). Received saved weight with shape (232,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #322 (named block6d_project_bn) due to mismatch in shape for weight block6d_project_bn/moving_mean:0. Weight expects shape (192,). Received saved weight with shape (232,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #322 (named block6d_project_bn) due to mismatch in shape for weight block6d_project_bn/moving_mean:0. Weight expects shape (192,). Received saved weight with shape (232,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #322 (named block6d_project_bn) due to mismatch in shape for weight block6d_project_bn/moving_variance:0. Weight expects shape (192,). Received saved weight with shape (232,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #322 (named block6d_project_bn) due to mismatch in shape for weight block6d_project_bn/moving_variance:0. Weight expects shape (192,). Received saved weight with shape (232,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #355 (named block7a_expand_conv) due to mismatch in shape for weight block7a_expand_conv/kernel:0. Weight expects shape (1, 1, 192, 1152). Received saved weight with shape (1392, 232, 1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #355 (named block7a_expand_conv) due to mismatch in shape for weight block7a_expand_conv/kernel:0. Weight expects shape (1, 1, 192, 1152). Received saved weight with shape (1392, 232, 1, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #356 (named block7a_expand_bn) due to mismatch in shape for weight block7a_expand_bn/gamma:0. Weight expects shape (1152,). Received saved weight with shape (1392,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #356 (named block7a_expand_bn) due to mismatch in shape for weight block7a_expand_bn/gamma:0. Weight expects shape (1152,). Received saved weight with shape (1392,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #356 (named block7a_expand_bn) due to mismatch in shape for weight block7a_expand_bn/beta:0. Weight expects shape (1152,). Received saved weight with shape (1392,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #356 (named block7a_expand_bn) due to mismatch in shape for weight block7a_expand_bn/beta:0. Weight expects shape (1152,). Received saved weight with shape (1392,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #356 (named block7a_expand_bn) due to mismatch in shape for weight block7a_expand_bn/moving_mean:0. Weight expects shape (1152,). Received saved weight with shape (1392,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #356 (named block7a_expand_bn) due to mismatch in shape for weight block7a_expand_bn/moving_mean:0. Weight expects shape (1152,). Received saved weight with shape (1392,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #356 (named block7a_expand_bn) due to mismatch in shape for weight block7a_expand_bn/moving_variance:0. Weight expects shape (1152,). Received saved weight with shape (1392,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #356 (named block7a_expand_bn) due to mismatch in shape for weight block7a_expand_bn/moving_variance:0. Weight expects shape (1152,). Received saved weight with shape (1392,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #358 (named block7a_dwconv) due to mismatch in shape for weight block7a_dwconv/depthwise_kernel:0. Weight expects shape (3, 3, 1152, 1). Received saved weight with shape (3, 3, 1392, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #358 (named block7a_dwconv) due to mismatch in shape for weight block7a_dwconv/depthwise_kernel:0. Weight expects shape (3, 3, 1152, 1). Received saved weight with shape (3, 3, 1392, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #359 (named block7a_bn) due to mismatch in shape for weight block7a_bn/gamma:0. Weight expects shape (1152,). Received saved weight with shape (1392,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #359 (named block7a_bn) due to mismatch in shape for weight block7a_bn/gamma:0. Weight expects shape (1152,). Received saved weight with shape (1392,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #359 (named block7a_bn) due to mismatch in shape for weight block7a_bn/beta:0. Weight expects shape (1152,). Received saved weight with shape (1392,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #359 (named block7a_bn) due to mismatch in shape for weight block7a_bn/beta:0. Weight expects shape (1152,). Received saved weight with shape (1392,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #359 (named block7a_bn) due to mismatch in shape for weight block7a_bn/moving_mean:0. Weight expects shape (1152,). Received saved weight with shape (1392,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #359 (named block7a_bn) due to mismatch in shape for weight block7a_bn/moving_mean:0. Weight expects shape (1152,). Received saved weight with shape (1392,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #359 (named block7a_bn) due to mismatch in shape for weight block7a_bn/moving_variance:0. Weight expects shape (1152,). Received saved weight with shape (1392,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #359 (named block7a_bn) due to mismatch in shape for weight block7a_bn/moving_variance:0. Weight expects shape (1152,). Received saved weight with shape (1392,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #363 (named block7a_se_reduce) due to mismatch in shape for weight block7a_se_reduce/kernel:0. Weight expects shape (1, 1, 1152, 48). Received saved weight with shape (58, 1392, 1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #363 (named block7a_se_reduce) due to mismatch in shape for weight block7a_se_reduce/kernel:0. Weight expects shape (1, 1, 1152, 48). Received saved weight with shape (58, 1392, 1, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #363 (named block7a_se_reduce) due to mismatch in shape for weight block7a_se_reduce/bias:0. Weight expects shape (48,). Received saved weight with shape (58,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #363 (named block7a_se_reduce) due to mismatch in shape for weight block7a_se_reduce/bias:0. Weight expects shape (48,). Received saved weight with shape (58,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #364 (named block7a_se_expand) due to mismatch in shape for weight block7a_se_expand/kernel:0. Weight expects shape (1, 1, 48, 1152). Received saved weight with shape (1392, 58, 1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #364 (named block7a_se_expand) due to mismatch in shape for weight block7a_se_expand/kernel:0. Weight expects shape (1, 1, 48, 1152). Received saved weight with shape (1392, 58, 1, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #364 (named block7a_se_expand) due to mismatch in shape for weight block7a_se_expand/bias:0. Weight expects shape (1152,). Received saved weight with shape (1392,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #364 (named block7a_se_expand) due to mismatch in shape for weight block7a_se_expand/bias:0. Weight expects shape (1152,). Received saved weight with shape (1392,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #366 (named block7a_project_conv) due to mismatch in shape for weight block7a_project_conv/kernel:0. Weight expects shape (1, 1, 1152, 320). Received saved weight with shape (384, 1392, 1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #366 (named block7a_project_conv) due to mismatch in shape for weight block7a_project_conv/kernel:0. Weight expects shape (1, 1, 1152, 320). Received saved weight with shape (384, 1392, 1, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #367 (named block7a_project_bn) due to mismatch in shape for weight block7a_project_bn/gamma:0. Weight expects shape (320,). Received saved weight with shape (384,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #367 (named block7a_project_bn) due to mismatch in shape for weight block7a_project_bn/gamma:0. Weight expects shape (320,). Received saved weight with shape (384,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #367 (named block7a_project_bn) due to mismatch in shape for weight block7a_project_bn/beta:0. Weight expects shape (320,). Received saved weight with shape (384,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #367 (named block7a_project_bn) due to mismatch in shape for weight block7a_project_bn/beta:0. Weight expects shape (320,). Received saved weight with shape (384,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #367 (named block7a_project_bn) due to mismatch in shape for weight block7a_project_bn/moving_mean:0. Weight expects shape (320,). Received saved weight with shape (384,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #367 (named block7a_project_bn) due to mismatch in shape for weight block7a_project_bn/moving_mean:0. Weight expects shape (320,). Received saved weight with shape (384,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #367 (named block7a_project_bn) due to mismatch in shape for weight block7a_project_bn/moving_variance:0. Weight expects shape (320,). Received saved weight with shape (384,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #367 (named block7a_project_bn) due to mismatch in shape for weight block7a_project_bn/moving_variance:0. Weight expects shape (320,). Received saved weight with shape (384,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #383 (named top_conv) due to mismatch in shape for weight top_conv/kernel:0. Weight expects shape (1, 1, 320, 1280). Received saved weight with shape (1536, 384, 1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #383 (named top_conv) due to mismatch in shape for weight top_conv/kernel:0. Weight expects shape (1, 1, 320, 1280). Received saved weight with shape (1536, 384, 1, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #384 (named top_bn) due to mismatch in shape for weight top_bn/gamma:0. Weight expects shape (1280,). Received saved weight with shape (1536,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #384 (named top_bn) due to mismatch in shape for weight top_bn/gamma:0. Weight expects shape (1280,). Received saved weight with shape (1536,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #384 (named top_bn) due to mismatch in shape for weight top_bn/beta:0. Weight expects shape (1280,). Received saved weight with shape (1536,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #384 (named top_bn) due to mismatch in shape for weight top_bn/beta:0. Weight expects shape (1280,). Received saved weight with shape (1536,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #384 (named top_bn) due to mismatch in shape for weight top_bn/moving_mean:0. Weight expects shape (1280,). Received saved weight with shape (1536,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #384 (named top_bn) due to mismatch in shape for weight top_bn/moving_mean:0. Weight expects shape (1280,). Received saved weight with shape (1536,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #384 (named top_bn) due to mismatch in shape for weight top_bn/moving_variance:0. Weight expects shape (1280,). Received saved weight with shape (1536,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading weights for layer #384 (named top_bn) due to mismatch in shape for weight top_bn/moving_variance:0. Weight expects shape (1280,). Received saved weight with shape (1536,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense\n",
    "\n",
    "num_classes = 34\n",
    "\n",
    "# Build model\n",
    "base_model = EfficientNetB0(weights=None, include_top=False, input_shape=(224, 224, 3))\n",
    "x = GlobalAveragePooling2D()(base_model.output)\n",
    "output = Dense(num_classes, activation='softmax')(x)\n",
    "model = Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "# Load weights\n",
    "model.load_weights(\"EfficientNet_weights.h5\", by_name=True, skip_mismatch=True)\n",
    "\n",
    "# Save as Keras V3 model\n",
    "model.save(\"../models/EfficientNet_full_model.keras\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89152bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
